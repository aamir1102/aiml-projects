{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from typing import Annotated, Sequence, Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.messages import AIMessage\n",
    "from langchain_classic import hub  # (you used langchain_classic in your file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI , GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='I am a large language model, trained by Google.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--5a8c74d3-29c6-4377-a2cc-a99c85906e13-0' usage_metadata={'input_tokens': 7, 'output_tokens': 244, 'total_tokens': 251, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 233}}\n",
      "[0.012518692761659622, -0.03623774275183678, -0.03517773747444153, 0.027096299454569817, 0.00037546473322436213, 0.037958353757858276, 0.05115729942917824, 0.04442358389496803, 0.028012443333864212, 0.01885560154914856, -0.09148337692022324, -0.016658557578921318, 0.04837500676512718, -0.031365275382995605, -0.03341354429721832, -0.04911463335156441, -0.026846593245863914, 0.028125353157520294, -0.08439544588327408, -0.0829039141535759, 0.016194429248571396, -0.009853485971689224, -0.012983525171875954, -0.011467834003269672, -0.03350166976451874, -0.003879848401993513, 0.030994614586234093, -0.057442475110292435, -0.010611471720039845, -0.025186140090227127, 0.005421465262770653, 0.004726813640445471, -0.019125469028949738, -0.0145800756290555, 0.010744846425950527, 0.04577207192778587, -0.03114592470228672, 0.016865529119968414, 0.04094040393829346, -0.11717008054256439, -0.03086400032043457, 0.048399683088064194, -0.022185666486620903, -0.0007263935403898358, -0.017749860882759094, -0.02145109325647354, 0.0407564677298069, 0.0343099981546402, -0.01630573347210884, 0.0002047317539108917, 0.059229105710983276, 0.0059610516764223576, -0.047248754650354385, 0.05883565545082092, 0.031086022034287453, -0.016139784827828407, -0.00999915786087513, -0.020710740238428116, 0.07372599095106125, -0.018627610057592392, -0.038417600095272064, -0.0024000967387109995, 0.014828556217253208, -0.008634589612483978, 0.04100299999117851, 0.02919835038483143, 0.02449200488626957, 0.026706406846642494, -0.04846113920211792, 0.04711958020925522, 0.005670466460287571, 0.015437545254826546, -0.06437812000513077, 0.030537236481904984, -0.04033263400197029, 0.006762307602912188, -0.03060615435242653, -0.005037557799369097, 0.03282521292567253, 0.0387842021882534, -0.015593389980494976, 0.00894684623926878, 0.05329788103699684, 0.0601995587348938, -0.041096281260252, 0.014613433741033077, 0.012860996648669243, -0.024080825969576836, -0.012073145247995853, -0.007486585061997175, 0.07515367120504379, 0.026928113773465157, -0.04125526174902916, 0.029428763315081596, 0.004625336267054081, -0.03347783535718918, -0.0842602327466011, -0.10873474925756454, 0.046129822731018066, 0.02564961276948452, 0.009145576506853104, -0.0020786907989531755, -0.011696990579366684, -0.010792188346385956, 0.04405972361564636, -0.024332694709300995, -0.029412413015961647, 0.003404712537303567, -0.024394119158387184, -0.04383762180805206, 0.04788494110107422, -0.04854670166969299, 0.054497331380844116, -0.06546921283006668, -0.007655561435967684, -0.07341939210891724, -0.031844984740018845, -0.004237544257193804, -0.038562119007110596, 0.005250453483313322, -0.00480599794536829, 0.03498849272727966, -0.006341809406876564, 0.08695300668478012, -0.00977086927741766, 0.023577416315674782, 0.0033010756596922874, -0.04418806731700897, -0.036818139255046844, -0.06319897621870041, 0.07189425826072693, -0.05416155979037285, -0.0013928125845268369, 0.05338830500841141, -0.04708325117826462, 0.0199894942343235, 0.05524268373847008, -0.027751777321100235, 0.018322331830859184, -0.05750321224331856, -0.004870101343840361, 0.03184744715690613, -0.0630241185426712, 0.01534327119588852, 0.016563381999731064, -0.05011996626853943, -0.03423359617590904, -0.0020388278644531965, -0.02354682981967926, -0.007925037294626236, 0.0122050940990448, 0.05552288144826889, 0.03245024383068085, -0.021826468408107758, -0.01170260738581419, 0.000327603513142094, 0.05647744983434677, -0.04977353289723396, 0.01873902790248394, -0.03948541358113289, -0.04722628369927406, -0.03706446662545204, -0.04163214936852455, -0.0248391292989254, -0.04238906502723694, -0.007445755880326033, 0.02423235774040222, -0.018428968265652657, 0.02939579449594021, 0.014721921645104885, -0.019804351031780243, -0.03005230613052845, -0.014725747518241405, -0.020732205361127853, 0.0012603435898199677, -0.05524416267871857, -0.034874577075242996, -0.056264251470565796, -0.0009209607378579676, -0.03189656883478165, 0.009775472804903984, 0.03497585654258728, -0.06240684911608696, -0.020558279007673264, -0.027622563764452934, -0.01221881341189146, -0.01684766635298729, 0.06474326550960541, 0.05971306934952736, 0.0018281274242326617, -0.011346944607794285, 0.04301062226295471, -0.0066814362071454525, -0.009669717401266098, 0.010731976479291916, 0.022096391767263412, 0.027892518788576126, -0.04551304876804352, 0.02534443326294422, 0.054805412888526917, 0.03464783728122711, 0.014243168756365776, -0.025248082354664803, -0.0016355110565200448, -0.030676744878292084, 0.042934395372867584, -0.04202258214354515, -0.07019104808568954, 0.025184614583849907, -0.012318404391407967, -0.017995230853557587, -0.011875527910888195, 0.0013073623413220048, -0.033621903508901596, 0.011882314458489418, -0.012248215265572071, 0.05755874514579773, 0.0037783225998282433, 0.026877252385020256, -0.041367676109075546, 0.031043529510498047, 0.05070667341351509, 0.02509939856827259, 0.06796799600124359, 0.008029081858694553, 0.06367135792970657, -0.043236516416072845, -0.013333671726286411, -0.022168587893247604, -0.04682208597660065, -0.006230093073099852, -0.019678259268403053, -0.025514207780361176, 0.03311949968338013, -0.03426281362771988, 0.004018268547952175, 0.057232558727264404, 0.015215537510812283, -0.010599990375339985, -0.003758971579372883, -0.0020084090065211058, -0.060361381620168686, 0.03443728759884834, 0.010663223452866077, -0.010832017287611961, 0.02914964035153389, 0.06822957843542099, 0.01876610517501831, 0.07927007973194122, -0.07685095816850662, -0.06098252162337303, 0.00041341030737385154, -0.03243326395750046, 0.024835793301463127, -0.06383737176656723, -0.019903769716620445, -0.008249903097748756, -0.06127018481492996, -0.00609798775985837, 0.03319157287478447, 0.059417009353637695, -0.027568059042096138, 0.01471917424350977, -0.10353630781173706, -0.012479095719754696, -0.0029932300094515085, -0.029244380071759224, -0.00545688159763813, 0.004695311188697815, -0.05556744337081909, 0.02495383284986019, -0.02372470125555992, -0.0022689425386488438, 0.021652519702911377, -0.05047198385000229, 0.027081387117505074, 0.001822356367483735, 0.03560991957783699, -0.07654215395450592, 0.03464890271425247, 0.03983033820986748, 0.007596711162477732, -0.00820134487003088, 0.016433056443929672, -0.04052489995956421, -0.05317716300487518, 0.019095338881015778, 0.025312190875411034, -0.02060031145811081, 0.023101920261979103, 0.022763198241591454, 0.05318830907344818, 0.022689035162329674, 0.04580517113208771, -0.02418431267142296, 0.005756509490311146, 0.0227394737303257, -0.008462236262857914, 0.014890947379171848, 0.025959135964512825, 0.0655631422996521, 0.049347080290317535, -0.0649702250957489, -0.004799894988536835, -0.02577640675008297, -0.021585550159215927, -0.029571639373898506, -0.03776778653264046, -0.03476656973361969, -0.04833543673157692, -0.011524934321641922, 0.01436570193618536, -0.010157293640077114, 0.025512751191854477, -0.020560992881655693, 0.008830257691442966, -0.07185208052396774, 0.008842254057526588, -0.06730465590953827, -0.03426032140851021, 0.023815058171749115, 0.01045922003686428, -0.0221498254686594, 0.016855722293257713, 0.02214805595576763, -0.00563858263194561, 0.037372421473264694, 0.014081068336963654, -0.000627673405688256, 0.03209219127893448, 0.01831839233636856, -0.01115434616804123, 0.007815935648977757, -0.03676748275756836, 0.04389002546668053, 0.02950260043144226, -0.08435370028018951, 0.046304523944854736, 0.05592359974980354, 0.11318342387676239, 3.902989192283712e-05, 0.003976206760853529, 0.03190291300415993, 0.026454634964466095, -0.030403388664126396, -0.07173648476600647, 0.0275344867259264, -0.018295731395483017, 0.008834141306579113, -0.053571369498968124, -0.011381423100829124, 0.037122730165719986, 0.021967831999063492, -0.05628304183483124, -0.06302008777856827, -0.029151905328035355, 0.01775461994111538, -0.010099999606609344, -0.007647380232810974, 0.004036938305944204, 0.019492236897349358, 0.03337069973349571, -0.023329518735408783, 0.07820428907871246, -0.017568793147802353, 0.013144304044544697, 0.0525190606713295, 0.0575278177857399, 0.021852001547813416, -0.018283449113368988, -0.012473837472498417, -0.010325700044631958, 0.0012296705972403288, -0.04114870727062225, 0.049336422234773636, 0.011148248799145222, -0.023351864889264107, 0.01849576085805893, 0.038280658423900604, -0.0712461918592453, -0.01973361149430275, -0.044761333614587784, -0.029651222750544548, 0.004280421882867813, -0.045621488243341446, 0.09187140315771103, -0.04828658699989319, -0.018675927072763443, -0.010195722803473473, 0.023510273545980453, 0.012555152177810669, 0.03710920363664627, 0.02312895841896534, 0.03566849231719971, -0.017556706443428993, 0.0016301128780469298, -0.01124767865985632, -0.02638448029756546, -0.021822530776262283, 0.0447160042822361, 0.025419902056455612, 0.013948207721114159, 0.06108173355460167, -0.08092902600765228, -0.04439651221036911, -0.06017359718680382, 0.04674016311764717, 0.010157673619687557, 0.01750018447637558, 0.014106757007539272, 0.017397280782461166, 0.028775108978152275, 0.04061347246170044, -0.015176225453615189, -0.06216379255056381, -0.06951109319925308, -0.0026321974582970142, -0.019868671894073486, 0.007292000576853752, 0.027097685262560844, -0.048658814281225204, 0.006863653659820557, 0.02216487191617489, -0.03659230098128319, 0.02679526060819626, -0.021725721657276154, -0.0010953237069770694, -0.01312750019133091, 0.01988554745912552, -0.005687573924660683, 0.01552630215883255, 0.00289959111250937, -0.0006070671952329576, -0.07300267368555069, -0.030238034203648567, 0.010913451202213764, -0.0185411237180233, 0.0035564254503697157, 0.009019523859024048, -0.007474066689610481, -0.00754526536911726, -4.561839159578085e-05, 0.017934652045369148, 0.035023387521505356, -0.05253135412931442, 0.042625412344932556, 0.04006103798747063, 0.020342931151390076, 0.011024750769138336, -0.02279829792678356, 0.039904262870550156, -0.06498732417821884, -0.006865274161100388, 0.010919824242591858, -0.0438656285405159, 0.007444495800882578, 0.020456699654459953, 0.007332334760576487, 0.006250091828405857, -0.015007092617452145, -0.05475427955389023, 0.02217233180999756, 0.09707270562648773, -0.01005181111395359, 0.016552360728383064, -0.00740497512742877, -0.034652285277843475, 0.009079323150217533, -0.03884193301200867, 0.01059007178992033, 0.005054936744272709, -0.004029028117656708, 0.014592057093977928, -0.03091176226735115, -0.02932140789926052, -0.04561452195048332, 0.028665395453572273, 0.040971480309963226, 0.01607353612780571, 0.008512832224369049, -0.041218094527721405, -0.03371405228972435, -0.024020763114094734, 0.03746791556477547, 0.047966256737709045, 0.010903412476181984, -0.04139113798737526, -0.0045763771049678326, 0.012038825079798698, -0.02330971322953701, 0.015643266960978508, 0.04083309695124626, 0.004894022364169359, -0.008949432522058487, -0.037692099809646606, -0.03239551931619644, 0.045114122331142426, -0.012821758165955544, -0.012918271124362946, -0.043928101658821106, 0.032840829342603683, 0.02697754092514515, -0.04787560924887657, -0.004240153357386589, -0.01916367933154106, -0.008400728926062584, -0.005713522434234619, -0.010850440710783005, 0.008764039725065231, -0.009628722444176674, 0.010193304158747196, 0.005497889593243599, 0.04360143095254898, 0.0290104690939188, 0.054670657962560654, 0.015213225036859512, -0.03969644382596016, 0.01732616126537323, -0.009322700090706348, 0.02114434354007244, -0.05047158896923065, -0.01013652328401804, -0.020307138562202454, -0.001544132479466498, 0.015356600284576416, -0.0475851371884346, -0.003982874099165201, -0.009103271178901196, 0.05216289684176445, -0.04030163213610649, -0.011333739385008812, 0.04742763563990593, 0.034940917044878006, 0.013490493409335613, -0.036716386675834656, 0.07834172248840332, 0.04623914882540703, 0.018064502626657486, -0.045583851635456085, 0.060875341296195984, -0.015086292289197445, -0.013840711675584316, 0.03470304235816002, 0.04566148295998573, 0.0011597158154472709, -0.010796240530908108, 0.021391738206148148, 0.028411371633410454, -0.04125775024294853, 0.04318983852863312, 0.02251148410141468, -0.05104152485728264, -0.018124330788850784, -0.0007521118968725204, 0.01972777210175991, 0.010831885039806366, -0.017963813617825508, 0.00930542778223753, -0.036153268069028854, -0.0505196675658226, 0.010095151141285896, -0.04545662924647331, 0.03737304359674454, 0.002340928418561816, -0.035730257630348206, 0.014667278155684471, 0.008507287129759789, -0.0029444796964526176, -0.01236264780163765, 0.03737995773553848, 0.04198315739631653, -0.01683664135634899, -0.006140850018709898, -0.04284239187836647, -0.008289591409265995, -0.03510654345154762, -0.01913795992732048, -0.025934631004929543, 0.02991476282477379, -0.05719323828816414, 0.013294177129864693, 0.013730845414102077, 0.021393723785877228, 0.030385473743081093, -0.038634516298770905, 0.016872910782694817, 0.029059814289212227, 0.004847659729421139, 0.054621849209070206, 0.02622702717781067, 0.022165508940815926, 0.025115272030234337, 0.003773147240281105, -0.00013876912998966873, 0.03559422865509987, 0.02754603698849678, -0.03608343377709389, 0.018636204302310944, -0.045546598732471466, -0.023706290870904922, -0.04214908927679062, 0.00893162190914154, 0.0547931082546711, -0.0430007129907608, -0.0013727123150601983, -0.019893551245331764, -0.030532920733094215, -0.06574578583240509, 0.05074842646718025, -0.004824800882488489, 0.0021483413875102997, 0.020576877519488335, 0.003385282587260008, -0.021614419296383858, -0.08725608885288239, -0.056396182626485825, -0.08448965102434158, -0.05506547540426254, -0.030453486368060112, -0.016547808423638344, 0.04787944629788399, 0.07378087937831879, 0.056122612208127975, -0.04297199100255966, -0.05870511010289192, 0.04280991852283478, -0.017878400161862373, -0.05333738774061203, 0.001618281239643693, -0.06375809758901596, 0.03691989183425903, 0.018877221271395683, 0.04801151901483536, -0.020393280312418938, -0.02034175395965576, 0.017661742866039276, -0.07154034078121185, -0.012733208946883678, -0.012135226279497147, -0.052409131079912186, -0.015307759866118431, 0.0048771691508591175, 0.03577109053730965, 0.09510818123817444, -0.06818883866071701, 0.015373767353594303, 0.029422074556350708, -0.029751241207122803, 0.05079738050699234, 0.03086705505847931, -0.028877142816781998, 0.022521670907735825, -0.045026011765003204, -0.02118918113410473, 0.0218913983553648, 0.014961226843297482, -5.713405698770657e-05, -0.005503848660737276, 0.05765504762530327, -0.0037858309224247932, 0.02410776913166046, -0.02111600711941719, -0.02422180585563183, 0.0050227222964167595, 0.012237816117703915, -0.019557209685444832, -0.05280531942844391, 0.026608165353536606, 0.00639713229611516, 0.0024344732519239187, 0.010603251866996288, -0.020162375643849373, -0.016201095655560493, 0.006738138385117054, 0.05487949028611183, 0.0005698130116797984, 0.05158922076225281, -0.013791133649647236, 0.017569005489349365, -0.03301624581217766, -0.012689064256846905, -0.024486571550369263, 0.037785470485687256, -0.04342205822467804, -0.03660697489976883, 0.0004170486645307392, 0.00725180609151721, -0.02983843721449375, 0.08136755228042603, -0.027667349204421043, -0.005279478617012501, -0.05188515782356262, -0.015521376393735409, 0.008956925012171268, -0.04741872474551201, 0.038155198097229004, -0.04407234117388725, 0.024176007136702538, -0.037952858954668045, -0.021443696692585945, -0.023215804249048233, -0.025918234139680862, -0.03803164139389992, 0.009271016344428062, 0.013934290036559105, -0.006307588890194893, 0.10413765162229538, 0.04201919957995415, 0.03521605581045151, -0.04081948846578598, -0.03962310403585434, -0.031802065670490265, 0.027915624901652336, -0.023932363837957382, 0.0059822676703333855, 0.011074645444750786, -0.015337517485022545, -0.0263056680560112, -0.039176952093839645, 0.07241053879261017, -0.025588160380721092, 0.00036717887269333005, 0.0512235127389431, 0.052833374589681625, 0.056751757860183716, 0.0006862719310447574, -0.03717155009508133, -0.04655462130904198, -0.02384798787534237, 0.07667730003595352, 0.06425092369318008, -0.009028569795191288, -0.058156926184892654, -0.006338919047266245, 0.013434655033051968, 0.02401171810925007, 0.03922107815742493, -0.010409368202090263, 0.03285791724920273, -0.024784471839666367, 0.05234086140990257, -0.004626173060387373, -0.0016643691342324018, -0.08181062340736389, -0.016887949779629707, 0.03144665062427521, -0.07752760499715805, -0.013268198817968369, -0.02601007930934429, -0.06845599412918091, -0.029691915959119797, -0.007359729614108801, 0.014776676893234253, 0.02546454221010208, -0.0014413149328902364, -0.021043654531240463, -0.0013637153897434473, -0.03427042067050934, 0.010171559639275074, 0.02670375443994999, -0.0319516621530056, 0.09769332408905029, -0.040732383728027344, 0.029234787449240685, -0.015274462290108204, -0.03250695765018463, -0.032357364892959595, 0.015325648710131645]\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"Hey , who are you ??\"))\n",
    "print(embeddings.embed_query(\"Hey , who are you ??\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/introduction/', 'title': 'Redirecting...', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n')],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/workflows/', 'title': 'Redirecting...', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n')],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/how-tos/map-reduce/', 'title': 'Redirecting...', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n')]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls=[\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/workflows/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/how-tos/map-reduce/\"\n",
    "]\n",
    "\n",
    "docs=[WebBaseLoader(url).load() for url in urls]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "## Add alll these text to vectordb\n",
    "\n",
    "vectorstore=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='retriever_vector_db_blog', description='Search and run information about Langgraph', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002207E11DD00>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000022075E48830>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002207E11DE40>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000022075E48830>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"what is langgraph\")\n",
    "\n",
    "### Retriever To Retriever Tools\n",
    "# from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retriever_vector_db_blog\",\n",
    "    \"Search and run information about Langgraph\"\n",
    ")\n",
    "\n",
    "retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={'source': 'https://www.elastic.co/blog/langchain-tutorial', 'title': 'LangChain tutorial: An intro to building LLM-powered apps | Elastic Blog', 'description': 'Unlock the potential of LangChain with this step-by-step LangChain tutorial. Learn how to build AI-powered apps from scratch and start creating today....', 'language': 'en'}, page_content='LangChain tutorial: An intro to building LLM-powered apps | Elastic BlogSkip to main contentTable of ContentsTable of contentsLangChain tutorial: A guide to building LLM-powered applicationsLangChain explainedHow does LangChain work?Core concepts of LangChainComponents and modulesIntegration with LLMsWorkflow managementSetting up LangChainInstallation and configurationDeveloping applications with LangChainStep 1: Import the OpenAI class from LangChainStep 2: Define a functional read data from a text file:Step 3: Initialize the OpenAI modelStep 4: Define a function to request a response from OpenAIStep 5: Read data from the text fileStep 6: Create a test promptStep 7: Get the response from GPT-3 and print itStep 8: Run the app and check the responseUse casesBuild LLM-powered apps using LangChainWhat you should do nextCloseLangChain tutorial: A guide to building LLM-powered applicationsByElastic Platform TeamFebruary 26, 2024Share on TwitterShare on TwitterShare on LinkedInShare on LinkedInShare on FacebookShare on FacebookShare by EmailShare by EmailPrint this pagePrintLarge language models (LLMs) like GPT-4 and LLaMA have created a whole world of possibilities over the past couple of years. It’s heralded a boom in AI tools and applications, and ChatGPT has become a household name seemingly overnight. But this boom wouldn’t be possible without the powerful tools and frameworks created to facilitate this new generation of apps.\\xa0One of these frameworks is LangChain, which makes it easy to build new apps using existing LLMs. It was developed by machine learning expert Harrison Chase and launched in 2022 as an open source project. This framework is a huge step in bridging the technical gap between existing language models and building new and varied applications.LangChain explainedIn simple terms, LangChain is a standardized interface that simplifies the process of building AI apps. It gives you a variety of tools you can use to connect different components and create complex workflows. This includes LLMs and various types of data sources. When a user interacts with the app, LangChain uses its connections to an LLM to process the request and generate appropriate responses. It can also use information and data from external sources like a document or database to provide more accurate and contextually relevant answers.For instance, if a user asks a question, LangChain will use the LLM to comprehend the question and formulate a response. But it will also pull from one or more external data sources to enhance its reply. This makes your application much more intelligent and capable of handling complex and specialized queries.Essentially, you’re augmenting the abilities of the LLM by providing it with data that is more relevant to the problems you want it to solve.Available as both a Python and TypeScript package, it has several impressive features:Model interaction: LangChain allows interaction with any language model, managing inputs and extracting information from outputs.Efficient integration: It provides efficient integration with popular AI platforms like OpenAI and Hugging Face.Flexibility and customization: LangChain offers flexibility, customization options, and powerful components to create a wide variety of applications across different industries.Core components: The framework consists of LangChain libraries, LangChain templates, LangServe, and LangSmith, which simplify the entire application lifecycle.\\xa0Standardized interfaces: It provides standardized interfaces, prompt management, and memory capabilities, enabling language models to interact with data sources.This combination of features makes it flexible, quick, scalable, and easy to use, which is music to the ears of any developers tempted to get started with AI.\\xa0How does LangChain work?LangChain is a modular framework that integrates with LLMs. It’s a standardized interface that abstracts away the complexities and difficulties of working with different LLM APIs — it’s the same process for integrating with GPT-4, LLaMA, or any other LLM you want to use. It also has dynamic LLM selection, which means developers can select the most appropriate LLM for the specific task they’re using LangChain to carry out.The modular design also facilitates the processing and transformation of input data into actionable outputs. It handles various data types, including text, code, and multimedia formats, and it provides tools for preprocessing, cleaning, and normalizing data. This is to ensure the data is suitable for consumption by the LLMs and may involve tokenization, normalization, and language identification.LangChain also processes the LLM’s output, transforming it into formats appropriate for the app or task-specific requirements. This includes things like formatting text, generating code snippets, and providing summaries of complex data.Core concepts of LangChainLangChain\\'s architecture is built on the concept of components and chains. Components represent reusable modules that perform specific tasks, such as processing input data, generating text formats, accessing external information, or managing workflows. Chains are sequences of components that work together to achieve a broader goal, such as summarizing a document, generating creative text formats, or providing personalized recommendations.Components and modulesIn LangChain, the terms \"components\" and \"modules\" are sometimes used interchangeably, but there is a subtle distinction between the two:\\xa0Components are the core building blocks of LangChain, representing specific tasks or functionalities. These are typically small and focused and can be reused across different applications and workflows.\\xa0Modules, on the other hand, combine multiple components to form more complex functionalities. LangChain even provides standard interfaces for a few of their main modules, including memory modules (a reusable building block that stores and manages data for use by large language models) and agents (a dynamic control unit that orchestrates chains based on real-time feedback and user interaction).\\xa0Like components, modules are reusable and can be combined together to create even more complex workflows. This is called a chain, where sequences of components or modules are put together to achieve a specific goal. Chains are fundamental to workflow orchestration in LangChain and are essential for building effective applications that handle a wide range of tasks.Integration with LLMsLangChain seamlessly integrates with LLMs by providing a standardized interface. But LangChain\\'s integration with LLMs goes beyond simply providing a connection mechanism. It also offers several features that optimize the use of LLMs for building language-based applications:Prompt management: LangChain enables you to craft effective prompts that help the LLMs understand the task and generate a useful response.Dynamic LLM selection: This allows you to select the most appropriate LLM for different tasks based on factors like complexity, accuracy requirements, and computational resources.Memory management integration: LangChain integrates with memory modules, which means LLMs can access and process external information.Agent-based management: This enables you to orchestrate complex LLM-based workflows that adapt to changing circumstances and user needs.Workflow managementIn LangChain, workflow management is the process of orchestrating and controlling the execution of chains and agents to solve a specific problem. This involves managing the flow of data, coordinating the execution of components, and ensuring that applications respond effectively to user interactions and changing circumstances. Here are some of the key workflow management components:Chain orchestration: LangChain coordinates the execution of chains to ensure tasks are performed in the correct order and data is correctly passed between components.Agent-based management: The use of agents is simplified with predefined templates and a user-friendly interface.State management: LangChain automatically tracks the state of the application, providing developers with a unified interface for accessing and modifying state information.Concurrency management: LangChain handles the complexities of concurrent execution, enabling developers to focus on the tasks and interactions without worrying about threading or synchronization issues.Setting up LangChainOne of the advantages of LangChain is that there are very few requirements to get started. For this guide, we’ll be using Python, so you’ll need to have Python 3.8 or later installed on your computer. That’s it!Installation and configurationThe first step is to install the core LangChain framework. The easiest way to do this is with this PIP command:pip install langchainCopy to clipboardCopy to clipboardThe next thing you need is an LLM for LangChain to interact with. We’ll use OpenAI in this example, but you can use any LLM you want for your app:pip install openaiCopy to clipboardCopy to clipboardFor OpenAI to work, you also need an API key to authenticate your requests. You can get one by creating an OpenAI account, going to the API keys section, and selecting “Create new secret key.” Once you have the key, keep it safe somewhere. You’ll need it shortly.Finally, create a text file called data.txt. This is going to be the external data source you use to give context to the LLM:In West Philadelphia born and raised\\nOn the playground was where I spent most of my days\\nChillin\\' out, maxin\\', relaxin\\', all cool\\nAnd all shootin\\' some b-ball outside of the school\\nCopy to clipboardCopy to clipboardNow it’s time for the fun bit!Developing applications with LangChainFor building this LangChain app, you’ll need to open your text editor or IDE of choice and create a new Python (.py) file in the same location as data.txt. You’re going to create a super basic app that sends a prompt to OpenAI’s GPT-3 LLM and prints the response.Looking for something a bit more advanced? Check out our guide to using Amazon Bedrock with Elasticsearch and Langchain.Step 1: Import the OpenAI class from LangChainAt the top of your Python script, add this import statement to pull in the OpenAI class from LangChain’s LLM module:from langchain.llms import OpenAICopy to clipboardCopy to clipboardStep 2: Define a functional read data from a text file:Define the function, so the app takes the file path as an argument. This will open the file for reading and return its contents:def read_data_from_file(file_path):\\n    with open(file_path, \\'r\\') as file:\\n        return file.read()Copy to clipboardCopy to clipboardStep 3: Initialize the OpenAI modelCreate an instance of the OpenAI class with your API key, replacing YOUR-OPENAI-KEY with the actual key you obtained from OpenAI:gpt3 = OpenAI(api_key=\\'YOUR-OPENAI-KEY\\')Copy to clipboardCopy to clipboardStep 4: Define a function to request a response from OpenAIWrite a function that takes a prompt as its argument and returns the response from the GPT-3 model:def get_response(prompt):\\n    return gpt3(prompt)\\nCopy to clipboardCopy to clipboardStep 5: Read data from the text fileSpecify the path to the text file and use the function you defined earlier to read its contents. You’ll then store the data in the external_data variable:file_path = \\'data.txt\\'\\nexternal_data = read_data_from_file(file_path)Copy to clipboardCopy to clipboardStep 6: Create a test promptThis is where you define the prompt you’re going to send to GPT-3. In this example, you’re going to ask it to read the text and tell you what TV show the text file is talking about:prompt = f\"Based on the following data: {external_data}, what TV show is this about?\"Copy to clipboardCopy to clipboardStep 7: Get the response from GPT-3 and print itCall a function that sends the prepared prompt and then retrieves and prints the response from GPT-3:print(\"Response:\", get_response(prompt))\\nCopy to clipboardCopy to clipboardStep 8: Run the app and check the responseOnce you’ve done all of this, you have a Python app that looks like this:from langchain.llms import OpenAI\\n\\n# Function to read data from a file\\ndef read_data_from_file(file_path):\\n    with open(file_path, \\'r\\') as file:\\n        return file.read()\\n\\n# Initialize the LLM\\ngpt3 = OpenAI(api_key=\\'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\\')\\n\\ndef get_response(prompt):\\n    return gpt3(prompt)\\n\\n# Read data from your text file\\nfile_path = \\'data.txt\\'\\nexternal_data = read_data_from_file(file_path)\\n\\n# Prepare your prompt including the external data\\nprompt = f\"Based on the following data: {external_data}, what TV show is this about?\"\\n\\n# Get the response from GPT-3\\nprint(\"Response:\", get_response(prompt))Copy to clipboardCopy to clipboardSo now all that’s left to do is run your Python app to make sure it works! Save the file, and run your app with this command in the terminal:python YOUR-APP-NAME.pyCopy to clipboardCopy to clipboardIf everything has gone to plan, you get a response that looks something like this:Response: \\nThis is the opening theme song for the popular 1990s TV show \"The Fresh Prince of Bel-Air\".Copy to clipboardCopy to clipboardUse casesThis example is an over-simplified demo, but the flexibility of LangChain means there are endless possibilities for building new AI apps. We couldn’t possibly try to list them all here, but we’ll run through a few case studies to highlight the various things you could build:Chatbot: Build your own chatbot where you can ask questions in natural language and maintain conversation history.\\xa0\\xa0Q&A app: Create an app where you can ask for the information you’re after, and it’ll find the answer from stored documents.Text search (BM25): Create your own text search app to query large amounts of data.Vector search: Build an app that searches for data similarities and filters metadata.Hybrid search (text and vector): Develop an AI that matches similar documents using both text and vector filtering.LangChain with your own LLM: Use LangChain to build an AI app that uses your own LLM with external data sources.Build LLM-powered apps using LangChainIt should be clear by now that by combining the power of LLMs with the context and extra information in external data sources, LangChain gives you unlimited possibilities. It’s also remarkably easy to get started, as shown in this LangChain tutorial. This ease of use combined with the flexibility and power of LangChain make it an ideal platform for developing a wide range of AI applications. Whether you are building a chatbot, a Q&A app, or a search engine, LangChain can help you create innovative and effective solutions.What you should do nextWhenever you\\'re ready, here are four ways we can help you harness insights from your business’ data:Start a free trial and see how Elastic can help your business.Tour our solutions to see how Elastic\\'s Search AI Platform works and how our solutions will fit your needs.Discover how to incorporate generative AI in the enterprise.Share this article with someone you know who\\'d enjoy reading it. Share it with them via email, LinkedIn, Twitter, or Facebook.Continue reading AI search resources Unlocking the potential of large language models: Elastic\\'s first code contribution to LangChainPrivacy-first AI search using LangChain and ElasticsearchBuild an app with AWS Bedrock, Elastic, and LangChainGetting started guide to open-source LLMsThe release and timing of any features or functionality described in this post remain at Elastic\\'s sole discretion. Any features or functionality not currently available may not be delivered on time or at all.In this blog post, we may have used or referred to third party generative AI tools, which are owned and operated by their respective owners. Elastic does not have any control over the third party tools and we have no responsibility or liability for their content, operation or use, nor for any loss or damage that may arise from your use of such tools. Please exercise caution when using AI tools with personal, sensitive or confidential information. Any data you submit may be used for AI training or other purposes. There is no guarantee that information you provide will be kept secure or confidential. You should familiarize yourself with the privacy practices and terms of use of any generative AI tools prior to use.\\xa0Elastic, Elasticsearch, ESRE, Elasticsearch Relevance Engine and associated marks are trademarks, logos or registered trademarks of Elasticsearch N.V. in the United States and other countries. All other company and product names are trademarks, logos or registered trademarks of their respective owners.ShareShare on TwitterShare on TwitterShare on LinkedInShare on LinkedInShare on FacebookShare on FacebookShare by EmailShare by EmailPrint this pagePrintSign up for Elastic Cloud free trialSpin up a fully loaded deployment on the cloud provider you choose. As the company behind Elasticsearch, we bring our features and support to your Elastic clusters in the cloud.Start free trialFollow usAbout usAbout ElasticLeadershipBlogNewsroomJoin usCareersCareer portalHow we hirePartnersFind a partnerPartner loginRequest accessBecome a partnerTrust & SecurityLegalTrust centerPrivacyTrade ComplianceEthics & ComplianceInvestor relationsInvestor resourcesGovernanceFinancialsStockExcellence AwardsPrevious winnersElastic{ON} TourBecome a sponsorAll eventsAbout usAbout ElasticLeadershipBlogNewsroomJoin usCareersCareer portalHow we hirePartnersFind a partnerPartner loginRequest accessBecome a partnerTrust & SecurityLegalTrust centerPrivacyTrade ComplianceEthics & ComplianceInvestor relationsInvestor resourcesGovernanceFinancialsStockExcellence AwardsPrevious winnersElastic{ON} TourBecome a sponsorAll eventsTrademarksTerms of UsePrivacySitemap© . Elasticsearch B.V. All Rights ReservedThis website and all associated content, software, discussion forums, products, and services are intended for professional use only. No consumer use of this website or its content is intended or directed.\\nElastic, Elasticsearch, and other related marks are trademarks, logos, or registered trademarks of Elasticsearch B.V. in the United States and other countries.\\nApache, Apache Lucene, Apache Hadoop, Hadoop, HDFS and the yellow elephant logo are trademarks of the Apache Software Foundation in the United States and/or other countries. All other brand names, product names, or trademarks belong to their respective owners.')]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# langchain_urls=[\n",
    "#     \"https://medium.com/munchy-bytes/exploring-langchain-ff13fff63340\",\n",
    "#     \"https://medium.com/@vikrampande783/introduction-to-langchain-9e09aae37e62\",\n",
    "# ]\n",
    "\n",
    "langchain_urls=[\n",
    "    \"https://www.elastic.co/blog/langchain-tutorial\"\n",
    "]\n",
    "\n",
    "docs=[WebBaseLoader(url).load() for url in langchain_urls]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "## Add alll these text to vectordb\n",
    "\n",
    "vectorstorelangchain=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "\n",
    "retrieverlangchain=vectorstorelangchain.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool_langchain=create_retriever_tool(\n",
    "    retrieverlangchain,\n",
    "    \"retriever_vector_langchain_blog\",\n",
    "    \"Search and run information about Langchain\"\n",
    ")\n",
    "\n",
    "tools=[retriever_tool,retriever_tool_langchain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "# ----------------\n",
    "# 1) STATE\n",
    "# ----------------\n",
    "class AgentState(TypedDict):\n",
    "    # Append new messages rather than replace\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    # Loop guard counter for rewrite → agent cycles\n",
    "    attempts: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# 2) ENRICHED PROMPTS\n",
    "# ----------------\n",
    "\n",
    "# 2a) System prompt for the \"agent\" node (tool orchestration)\n",
    "AGENT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an agent orchestrating a Retrieval-Augmented Generation (RAG) workflow.\n",
    "\n",
    "Core rules:\n",
    "- Decide whether to use a retriever tool based on the user question and conversation state.\n",
    "- Prefer using tools when the question requires facts, definitions, documentation, or content that should be grounded in sources.\n",
    "- If the best answer is common knowledge and you are confident, you MAY answer directly, but keep answers brief and non-speculative.\n",
    "- NEVER fabricate citations. If you use tool results, cite the sources clearly (e.g., “Source: <doc-title-or-URL>”).\n",
    "- If retrieved documents are irrelevant, ask for clarification or propose a better query (the graph will route to rewrite).\n",
    "- Be concise, accurate, and helpful. If you are uncertain, say so and propose next steps.\n",
    "\n",
    "Output formatting:\n",
    "- Use clear, short paragraphs and bullet points where helpful.\n",
    "- Include sources only when you’ve grounded content on retrieved context.\n",
    "\"\"\"\n",
    "\n",
    "# 2b) Enriched RAG answer prompt (used in `generate`)\n",
    "RAG_PROMPT = PromptTemplate(\n",
    "    template=(\n",
    "        \"You are a careful assistant answering the user's question using ONLY the provided context.\\n\\n\"\n",
    "        \"Question:\\n{question}\\n\\n\"\n",
    "        \"Context (retrieved passages):\\n{context}\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"- Ground your answer strictly in the context above; do not invent facts.\\n\"\n",
    "        \"- If the context is insufficient, explicitly say what is missing and propose what to retrieve next.\\n\"\n",
    "        \"- Summarize and synthesize across passages; do not quote excessively unless necessary.\\n\"\n",
    "        \"- Include concise citations for any factual claims derived from the context. Use this style:\\n\"\n",
    "        \"    • Source: <short-title-or-URL>\\n\"\n",
    "        \"- Keep the tone professional and clear. Prefer bullet points if listing items.\\n\"\n",
    "        \"- If there are multiple interpretations or edge cases, surface them explicitly.\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    ),\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "# 2c) Enriched relevance grader prompt (used in `grade_documents`)\n",
    "RELEVANCE_GRADER_PROMPT = PromptTemplate(\n",
    "    template=(\n",
    "        \"You are evaluating whether a retrieved document is relevant to the user's question.\\n\\n\"\n",
    "        \"User question:\\n{question}\\n\\n\"\n",
    "        \"Retrieved document content:\\n{context}\\n\\n\"\n",
    "        \"Guidelines:\\n\"\n",
    "        \"- Consider semantic relevance: concepts, definitions, mechanisms, workflows, APIs, or terminology that directly answer or clarify the question.\\n\"\n",
    "        \"- Superficial keyword overlaps WITHOUT substantive connection are NOT sufficient.\\n\"\n",
    "        \"- Exact match is not required; paraphrases or closely related explanations count as relevant.\\n\"\n",
    "        \"- If the document discusses a different library, tool, version, or unrelated topic, grade it as NOT relevant.\\n\"\n",
    "        \"- Be conservative: prefer 'no' unless you see a clear path to answer the question using the document.\\n\\n\"\n",
    "        \"Provide a binary score: 'yes' if relevant, 'no' if not.\"\n",
    "    ),\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "# 2d) Enriched rewrite prompt (used in `rewrite`)\n",
    "REWRITE_PROMPT_TEMPLATE = \"\"\"\\\n",
    "You are improving a user query for a RAG system.\n",
    "\n",
    "Task:\n",
    "- Infer the underlying intent and information need.\n",
    "- Identify domain-specific terms, entities, APIs, features, or frameworks related to the question.\n",
    "- Add clarifying constraints only if they are implied (e.g., version, scope, type of output).\n",
    "- Remove ambiguity and make the query more retrievable.\n",
    "- Keep it concise and specific (ideally one sentence).\n",
    "\n",
    "Original question:\n",
    "-------\n",
    "{question}\n",
    "-------\n",
    "\n",
    "Return ONLY the improved query, no explanations.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# 3) NODES (agent, generate, grade_documents, rewrite) with enriched prompts\n",
    "# ----------------\n",
    "\n",
    "def agent(state: AgentState):\n",
    "    \"\"\"Agent decides whether to call tools (retriever) or end.\"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = list(state[\"messages\"])\n",
    "    # Prepend a system message to improve tool-use behavior\n",
    "    system_msg = SystemMessage(content=AGENT_SYSTEM_PROMPT)\n",
    "    messages = [system_msg] + messages\n",
    "\n",
    "    # Bind tools as before\n",
    "    # Assumes `tools` variable exists: [retriever_tool, retriever_tool_langchain]\n",
    "    model = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\")\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state: AgentState) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"Determine whether retrieved documents are relevant.\"\"\"\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Data model for structured output\n",
    "    from pydantic import BaseModel, Field\n",
    "    class Grade(BaseModel):\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM with structured output\n",
    "    model = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\")\n",
    "    llm_with_tool = model.with_structured_output(Grade)\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # Extract last HumanMessage as question\n",
    "    question = None\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            question = msg.content\n",
    "            break\n",
    "    if question is None:\n",
    "        question = messages[0].content\n",
    "\n",
    "    docs = last_message.content\n",
    "    chain = RELEVANCE_GRADER_PROMPT | llm_with_tool\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "    score = scored_result.binary_score.strip().lower()\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        return \"rewrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: AgentState):\n",
    "    \"\"\"Generate grounded answer using enriched RAG prompt.\"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Extract last HumanMessage as question\n",
    "    question = None\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            question = msg.content\n",
    "            break\n",
    "    if question is None:\n",
    "        question = messages[0].content\n",
    "\n",
    "    # Last tool output contains retrieved docs\n",
    "    last_message = messages[-1]\n",
    "    docs = last_message.content\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\")\n",
    "    rag_chain = RAG_PROMPT | model | StrOutputParser()\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "\n",
    "    return {\"messages\": [AIMessage(content=response)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state: AgentState):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question, but only if attempts < 3.\n",
    "    If attempts >= 3, skip the LLM call and just propagate the current state.\n",
    "    \"\"\"\n",
    "    current_attempts = state.get(\"attempts\", 0)\n",
    "\n",
    "    # Guard BEFORE any LLM call\n",
    "    if current_attempts >= 2:\n",
    "        print(\"---SKIPPING LLM CALL: max rewrite attempts reached---\")\n",
    "        return {\"attempts\": current_attempts}\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    # Extract last HumanMessage as question\n",
    "    question = None\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            question = msg.content\n",
    "            break\n",
    "    if question is None:\n",
    "        question = messages[0].content\n",
    "\n",
    "    rewrite_prompt = PromptTemplate(\n",
    "        template=REWRITE_PROMPT_TEMPLATE, input_variables=[\"question\"]\n",
    "    )\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\")\n",
    "    chain = rewrite_prompt | model | StrOutputParser()\n",
    "    improved_query = chain.invoke({\"question\": question})\n",
    "\n",
    "    current_attempts += 1\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=improved_query)],\n",
    "        \"attempts\": current_attempts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# 4) ROUTING GUARD\n",
    "# ----------------\n",
    "def route_after_rewrite(state: AgentState) -> Literal[\"agent\", \"end\"]:\n",
    "    tries = state.get(\"attempts\", 0)\n",
    "    print(f\"---REWRITE ATTEMPTS: {tries}---\")\n",
    "    if tries >= 2:\n",
    "        print(\"---TERMINATING: max rewrite attempts reached---\")\n",
    "        return \"end\"\n",
    "    return \"agent\"\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# 5) GRAPH WIRING\n",
    "# ----------------\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Assumes your tool setup exists:\n",
    "# retriever_tool, retriever_tool_langchain, tools = [retriever_tool, retriever_tool_langchain]\n",
    "retrieve = ToolNode([retriever_tool, retriever_tool_langchain])\n",
    "\n",
    "workflow.add_node(\"agent\", agent)       # agent (decides tools/end)\n",
    "workflow.add_node(\"retrieve\", retrieve) # retrieval\n",
    "workflow.add_node(\"rewrite\", rewrite)   # query rewriting\n",
    "workflow.add_node(\"generate\", generate) # final answer\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    "    {\"tools\": \"retrieve\", END: END},\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents,  # returns \"generate\" or \"rewrite\"\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"rewrite\",\n",
    "    route_after_rewrite,\n",
    "    {\"agent\": \"agent\", \"end\": END},\n",
    ")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "---TRANSFORM QUERY---\n",
      "---REWRITE ATTEMPTS: 1---\n",
      "---CALL AGENT---\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "---TRANSFORM QUERY---\n",
      "---REWRITE ATTEMPTS: 2---\n",
      "---TERMINATING: max rewrite attempts reached---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is Langgraph?', additional_kwargs={}, response_metadata={}, id='4fc5b5d9-4c79-48da-984c-d8030abbde16'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever_vector_db_blog', 'arguments': '{\"query\": \"What is Langgraph?\"}'}, '__gemini_function_call_thought_signatures__': {'646fd733-14be-4c3a-8a97-f4f43476e2bd': 'CpADAdHtim8ozs4PMMNQEflx9fAfYDgJMlYkIdlcv4mv/7np4Rx/2TBWaPC35oI4Ob+yxJnyCD/H0XjFba0e11OxhJgEFUav+F2GtPv/4TJPhS5VgBas5TVXRl3mKYROddhjBNzNASN8jHQv38VsDpQAKuGYSlT8XD0MOJuWZx1ocH4uXU1lRkh1SKeuMjE3YFAFpsQ9rrEH6yaQOyDIEwHUUInw+c1QD64O3BHIBdq98q1Pp6NVkIA/Zu17r5UoGmV3LS7VtUo9YJ3n+HrsfRJ3Hfdj5I31e09kIBhpPFjE4PpUzVssTmPjx4dTJ5QZoqGNdyJPc15p850rbGIOmOyoGfRmHSrr6hdrG7iSsc9HKWccSa9jJKt9Rxbs8nuSFoNQxvnznwxo53rIoYQGxaTB8s3lCSSQ+FpbA1tB9iOn8JiDp68dX9P5Z3td4eFsFQ4bMhXAUy0eHygPtq6LtO0FnEUOj89fHoXm8zWPr7TO2IjAgexz1sXLXm4u5H2STkxSv0K5WeREy6LEPyDZqqnhFw=='}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--1bc80629-4dd1-44c1-8165-e0f2a5c33fac-0', tool_calls=[{'name': 'retriever_vector_db_blog', 'args': {'query': 'What is Langgraph?'}, 'id': '646fd733-14be-4c3a-8a97-f4f43476e2bd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 309, 'output_tokens': 102, 'total_tokens': 411, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 78}}),\n",
       "  ToolMessage(content='Redirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...', name='retriever_vector_db_blog', id='573cc8e3-26b6-4b8d-9162-173d5897bff9', tool_call_id='646fd733-14be-4c3a-8a97-f4f43476e2bd'),\n",
       "  HumanMessage(content=\"Describe Langgraph's purpose and primary functionalities for developing stateful LLM applications.\", additional_kwargs={}, response_metadata={}, id='9d4468b8-eb2e-400e-99dc-4dcc7384ddae'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever_vector_db_blog', 'arguments': '{\"query\": \"Langgraph\\'s purpose and primary functionalities\"}'}, '__gemini_function_call_thought_signatures__': {'92c6d56e-3a3e-47df-aa0d-e7170cdcc5fe': 'CrkDAdHtim/qvYfcDw+bKUAm6XQpQt3Uo28A44/0Vx6lcV45B2w5syY0LojwKn0TMuJav+9vLMO0y1GAe0BScRj1bObl2uMO8NUI5Q+PT7RlYHMR1NUDYnCaVoMF/9MQU7rli3P2IpkHCQp+d9WOYe3iFGD8GprdXGqyu6nj5Zk2ED/9ykhew/lxgQEkr1ReumVfwX0g96Rtj/S/uSHc7KB9F3hNlHATJ9ACeBD8Lk+0YR8ljwi2D2M3BRgZeegCSHOHDCcjsQ8UTWaTKLGHXM6nf6KTGQzm5LdtDx5g1M658SeNmyG24UP6BBfpqWRZl0lp6r9MokDYbGD5j6Givws/9KaEyjnolupVwKbebLWrJQhSHjMEdB5/q2PzOrZ9wxpxDJUGE7M9Innx/IjeH2A5O7UILXCT2txW4at7TzTk7vcVyQbM6+QFCdHG99ko5iRkxwgylOMgYLeZkhfJ1XIFnrJvfCSzgrjY4k7XNl4wqrrZ4jioY2zdJhyOaLg9xSZA6xpfJBvtQZJBKh805Bf+KqHuQkRC+NXok3ROjbGs6/aZtYjUyJ/XpyX8x0gdVwDf9d6h893e2YPG'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--e601ffee-a8f2-481b-beb8-66eadf507f89-0', tool_calls=[{'name': 'retriever_vector_db_blog', 'args': {'query': \"Langgraph's purpose and primary functionalities\"}, 'id': '92c6d56e-3a3e-47df-aa0d-e7170cdcc5fe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 433, 'output_tokens': 121, 'total_tokens': 554, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 94}}),\n",
       "  ToolMessage(content='Redirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...', name='retriever_vector_db_blog', id='d61ace63-fe83-437a-98b1-9e7828dda552', tool_call_id='92c6d56e-3a3e-47df-aa0d-e7170cdcc5fe'),\n",
       "  HumanMessage(content=\"Explain Langgraph's core purpose and key features for stateful LLM application development.\", additional_kwargs={}, response_metadata={}, id='5b62acaf-cf74-4698-98c0-bbb1e6c856cd')],\n",
       " 'attempts': 2}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------\n",
    "# 6) SAFE INVOCATION (seed attempts=0)\n",
    "# ----------------\n",
    "graph.invoke({\"messages\": \"What is Langgraph?\", \"attempts\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS RELEVANT---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is Langchain?', additional_kwargs={}, response_metadata={}, id='577a62b4-197c-4b1d-8245-0a50e8668db8'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever_vector_langchain_blog', 'arguments': '{\"query\": \"Langchain\"}'}, '__gemini_function_call_thought_signatures__': {'7050c9a3-eb9f-4552-b7f9-de0cccfa7e86': 'CtwCAdHtim8VYlrxLAncaGkuerivtWE387BDzrcijj89oj67rRF5cyuXzmm3Mlx2ccJsWqp6nhGJctL+Zxx917CTrb2EQOoxS362LkRKKW2SYD8GzlGWbOfk6zje8eLoRpV3s+xNOUqUyRtP4rvVsMXYs5YSMwoylmHnOi5m8TILOUrrkxpI9hlkfM3xyMbNXDxubx16BMPNNKnKXyxqAaOx3ir1lCU1lyAyhQcuvrhVEMC6jX8Y1EpDpStkQDl+vYgidZcm9CpyWvCoO5kwhiXyK9rIG4yClb+1dyJ3WyN5AJlpPnN1tZXbETaZ3iBKRQdJo6Kugh7jbr9+7YofukLH9n7tNh43QMx8xNO4DCZojIAz0ysauMZtonUIJW/blmTAlwHhbVTTTQc//OAUr1aWToECi5Bp5/oMe3DUnUFRmp2L35Fgu3TgtMpL5GUuHwGA0yc5G60MsKzN8K5C'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--14a7ea5d-c5d7-4a69-8557-4531554d8fde-0', tool_calls=[{'name': 'retriever_vector_langchain_blog', 'args': {'query': 'Langchain'}, 'id': '7050c9a3-eb9f-4552-b7f9-de0cccfa7e86', 'type': 'tool_call'}], usage_metadata={'input_tokens': 309, 'output_tokens': 92, 'total_tokens': 401, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 70}}),\n",
       "  ToolMessage(content='Platform TeamFebruary 26, 2024Share on TwitterShare on TwitterShare on LinkedInShare on LinkedInShare on FacebookShare on FacebookShare by EmailShare by EmailPrint this pagePrintLarge language models (LLMs) like GPT-4 and LLaMA have created a whole world of possibilities over the past couple of years. It’s heralded a boom in AI tools and applications, and ChatGPT has become a household name seemingly overnight. But this boom wouldn’t be possible without the powerful tools and frameworks created to facilitate this new generation of apps.\\xa0One of these frameworks is LangChain, which makes it easy to build new apps using existing LLMs. It was developed by machine learning expert Harrison Chase and launched in 2022 as an open source project. This framework is a huge step in bridging the technical gap between existing language models and building new and varied applications.LangChain explainedIn simple terms, LangChain is a standardized interface that simplifies the process of building AI\\n\\nto interact with data sources.This combination of features makes it flexible, quick, scalable, and easy to use, which is music to the ears of any developers tempted to get started with AI.\\xa0How does LangChain work?LangChain is a modular framework that integrates with LLMs. It’s a standardized interface that abstracts away the complexities and difficulties of working with different LLM APIs — it’s the same process for integrating with GPT-4, LLaMA, or any other LLM you want to use. It also has dynamic LLM selection, which means developers can select the most appropriate LLM for the specific task they’re using LangChain to carry out.The modular design also facilitates the processing and transformation of input data into actionable outputs. It handles various data types, including text, code, and multimedia formats, and it provides tools for preprocessing, cleaning, and normalizing data. This is to ensure the data is suitable for consumption by the LLMs and may involve tokenization,\\n\\nabilities of the LLM by providing it with data that is more relevant to the problems you want it to solve.Available as both a Python and TypeScript package, it has several impressive features:Model interaction: LangChain allows interaction with any language model, managing inputs and extracting information from outputs.Efficient integration: It provides efficient integration with popular AI platforms like OpenAI and Hugging Face.Flexibility and customization: LangChain offers flexibility, customization options, and powerful components to create a wide variety of applications across different industries.Core components: The framework consists of LangChain libraries, LangChain templates, LangServe, and LangSmith, which simplify the entire application lifecycle.\\xa0Standardized interfaces: It provides standardized interfaces, prompt management, and memory capabilities, enabling language models to interact with data sources.This combination of features makes it flexible, quick, scalable, and\\n\\nsimple terms, LangChain is a standardized interface that simplifies the process of building AI apps. It gives you a variety of tools you can use to connect different components and create complex workflows. This includes LLMs and various types of data sources. When a user interacts with the app, LangChain uses its connections to an LLM to process the request and generate appropriate responses. It can also use information and data from external sources like a document or database to provide more accurate and contextually relevant answers.For instance, if a user asks a question, LangChain will use the LLM to comprehend the question and formulate a response. But it will also pull from one or more external data sources to enhance its reply. This makes your application much more intelligent and capable of handling complex and specialized queries.Essentially, you’re augmenting the abilities of the LLM by providing it with data that is more relevant to the problems you want it to', name='retriever_vector_langchain_blog', id='3f407031-eba2-4c9d-b013-734a0aab3f0d', tool_call_id='7050c9a3-eb9f-4552-b7f9-de0cccfa7e86'),\n",
       "  AIMessage(content='LangChain is a modular, open-source framework and standardized interface designed to simplify the process of building new AI applications using existing large language models (LLMs) such as GPT-4 and LLaMA (Platform Team, February 26, 2024).\\n\\nKey aspects of LangChain:\\n*   **Purpose** It makes it easy to build new apps with LLMs, bridging the technical gap between language models and varied applications (Platform Team, February 26, 2024). It simplifies the process of building AI apps that interact with data sources (Platform Team, February 26, 2024).\\n*   **Functionality** It abstracts away the complexities of working with different LLM APIs, providing a consistent process for integration. It also offers dynamic LLM selection, allowing developers to choose the most suitable LLM for specific tasks (Platform Team, February 26, 2024). LangChain augments LLM abilities by providing them with relevant data, processing and transforming input data (including text, code, and multimedia) into actionable outputs, and handling data preprocessing (Platform Team, February 26, 2024).\\n*   **Availability** It was developed by Harrison Chase and launched in 2022 as an open-source project, available as both a Python and TypeScript package (Platform Team, February 26, 2024).', additional_kwargs={}, response_metadata={}, id='bd67952b-4d88-4d0f-9376-32663257280b')],\n",
       " 'attempts': 0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\": \"What is Langchain?\", \"attempts\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is Machine learning?', additional_kwargs={}, response_metadata={}, id='ebdb9424-a018-4531-a314-ac562792a3ce'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Machine learning is a subset of artificial intelligence (AI) that enables systems to learn from data, identify patterns, and make decisions with minimal human intervention. It focuses on the development of algorithms that can analyze and interpret data, allowing them to \"learn\" and improve their performance over time without being explicitly programmed for every task.', 'extras': {'signature': 'CrMBAdHtim86p+vKzt86ZPW47B2GqnOZeIC/6W/QRay36n68a0ny4Sf040hQFlXAvMtcCiX5x+EFYozvdL3KTbiLK535wNzknlsGeAgnfbLCTqMRZXjWDORvooP4dVCf6uu8Zj0LIu+w7vpSobT19b7I4IT17jctf65jRKIfseSMUVXnSZzndppFm+ZLWY6P5NGevhy1M1GAr9ZMK2JSBzMuVwcYNQPXvbxDIsdnYVpmwdl/Xy8='}}], additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--86923985-4515-43e3-83fc-4d14fdf79a76-0', usage_metadata={'input_tokens': 309, 'output_tokens': 94, 'total_tokens': 403, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 30}})],\n",
       " 'attempts': 0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\": \"What is Machine learning?\", \"attempts\": 0})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
