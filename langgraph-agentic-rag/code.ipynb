{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "# os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI , GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hey there!\\n\\nI am a large language model, trained by Google.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--4abefa7c-50f6-48a1-9ed4-15dbad4c243c-0' usage_metadata={'input_tokens': 7, 'output_tokens': 270, 'total_tokens': 277, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 255}}\n",
      "[0.012518692761659622, -0.03623774275183678, -0.03517773747444153, 0.027096299454569817, 0.00037546473322436213, 0.037958353757858276, 0.05115729942917824, 0.04442358389496803, 0.028012443333864212, 0.01885560154914856, -0.09148337692022324, -0.016658557578921318, 0.04837500676512718, -0.031365275382995605, -0.03341354429721832, -0.04911463335156441, -0.026846593245863914, 0.028125353157520294, -0.08439544588327408, -0.0829039141535759, 0.016194429248571396, -0.009853485971689224, -0.012983525171875954, -0.011467834003269672, -0.03350166976451874, -0.003879848401993513, 0.030994614586234093, -0.057442475110292435, -0.010611471720039845, -0.025186140090227127, 0.005421465262770653, 0.004726813640445471, -0.019125469028949738, -0.0145800756290555, 0.010744846425950527, 0.04577207192778587, -0.03114592470228672, 0.016865529119968414, 0.04094040393829346, -0.11717008054256439, -0.03086400032043457, 0.048399683088064194, -0.022185666486620903, -0.0007263935403898358, -0.017749860882759094, -0.02145109325647354, 0.0407564677298069, 0.0343099981546402, -0.01630573347210884, 0.0002047317539108917, 0.059229105710983276, 0.0059610516764223576, -0.047248754650354385, 0.05883565545082092, 0.031086022034287453, -0.016139784827828407, -0.00999915786087513, -0.020710740238428116, 0.07372599095106125, -0.018627610057592392, -0.038417600095272064, -0.0024000967387109995, 0.014828556217253208, -0.008634589612483978, 0.04100299999117851, 0.02919835038483143, 0.02449200488626957, 0.026706406846642494, -0.04846113920211792, 0.04711958020925522, 0.005670466460287571, 0.015437545254826546, -0.06437812000513077, 0.030537236481904984, -0.04033263400197029, 0.006762307602912188, -0.03060615435242653, -0.005037557799369097, 0.03282521292567253, 0.0387842021882534, -0.015593389980494976, 0.00894684623926878, 0.05329788103699684, 0.0601995587348938, -0.041096281260252, 0.014613433741033077, 0.012860996648669243, -0.024080825969576836, -0.012073145247995853, -0.007486585061997175, 0.07515367120504379, 0.026928113773465157, -0.04125526174902916, 0.029428763315081596, 0.004625336267054081, -0.03347783535718918, -0.0842602327466011, -0.10873474925756454, 0.046129822731018066, 0.02564961276948452, 0.009145576506853104, -0.0020786907989531755, -0.011696990579366684, -0.010792188346385956, 0.04405972361564636, -0.024332694709300995, -0.029412413015961647, 0.003404712537303567, -0.024394119158387184, -0.04383762180805206, 0.04788494110107422, -0.04854670166969299, 0.054497331380844116, -0.06546921283006668, -0.007655561435967684, -0.07341939210891724, -0.031844984740018845, -0.004237544257193804, -0.038562119007110596, 0.005250453483313322, -0.00480599794536829, 0.03498849272727966, -0.006341809406876564, 0.08695300668478012, -0.00977086927741766, 0.023577416315674782, 0.0033010756596922874, -0.04418806731700897, -0.036818139255046844, -0.06319897621870041, 0.07189425826072693, -0.05416155979037285, -0.0013928125845268369, 0.05338830500841141, -0.04708325117826462, 0.0199894942343235, 0.05524268373847008, -0.027751777321100235, 0.018322331830859184, -0.05750321224331856, -0.004870101343840361, 0.03184744715690613, -0.0630241185426712, 0.01534327119588852, 0.016563381999731064, -0.05011996626853943, -0.03423359617590904, -0.0020388278644531965, -0.02354682981967926, -0.007925037294626236, 0.0122050940990448, 0.05552288144826889, 0.03245024383068085, -0.021826468408107758, -0.01170260738581419, 0.000327603513142094, 0.05647744983434677, -0.04977353289723396, 0.01873902790248394, -0.03948541358113289, -0.04722628369927406, -0.03706446662545204, -0.04163214936852455, -0.0248391292989254, -0.04238906502723694, -0.007445755880326033, 0.02423235774040222, -0.018428968265652657, 0.02939579449594021, 0.014721921645104885, -0.019804351031780243, -0.03005230613052845, -0.014725747518241405, -0.020732205361127853, 0.0012603435898199677, -0.05524416267871857, -0.034874577075242996, -0.056264251470565796, -0.0009209607378579676, -0.03189656883478165, 0.009775472804903984, 0.03497585654258728, -0.06240684911608696, -0.020558279007673264, -0.027622563764452934, -0.01221881341189146, -0.01684766635298729, 0.06474326550960541, 0.05971306934952736, 0.0018281274242326617, -0.011346944607794285, 0.04301062226295471, -0.0066814362071454525, -0.009669717401266098, 0.010731976479291916, 0.022096391767263412, 0.027892518788576126, -0.04551304876804352, 0.02534443326294422, 0.054805412888526917, 0.03464783728122711, 0.014243168756365776, -0.025248082354664803, -0.0016355110565200448, -0.030676744878292084, 0.042934395372867584, -0.04202258214354515, -0.07019104808568954, 0.025184614583849907, -0.012318404391407967, -0.017995230853557587, -0.011875527910888195, 0.0013073623413220048, -0.033621903508901596, 0.011882314458489418, -0.012248215265572071, 0.05755874514579773, 0.0037783225998282433, 0.026877252385020256, -0.041367676109075546, 0.031043529510498047, 0.05070667341351509, 0.02509939856827259, 0.06796799600124359, 0.008029081858694553, 0.06367135792970657, -0.043236516416072845, -0.013333671726286411, -0.022168587893247604, -0.04682208597660065, -0.006230093073099852, -0.019678259268403053, -0.025514207780361176, 0.03311949968338013, -0.03426281362771988, 0.004018268547952175, 0.057232558727264404, 0.015215537510812283, -0.010599990375339985, -0.003758971579372883, -0.0020084090065211058, -0.060361381620168686, 0.03443728759884834, 0.010663223452866077, -0.010832017287611961, 0.02914964035153389, 0.06822957843542099, 0.01876610517501831, 0.07927007973194122, -0.07685095816850662, -0.06098252162337303, 0.00041341030737385154, -0.03243326395750046, 0.024835793301463127, -0.06383737176656723, -0.019903769716620445, -0.008249903097748756, -0.06127018481492996, -0.00609798775985837, 0.03319157287478447, 0.059417009353637695, -0.027568059042096138, 0.01471917424350977, -0.10353630781173706, -0.012479095719754696, -0.0029932300094515085, -0.029244380071759224, -0.00545688159763813, 0.004695311188697815, -0.05556744337081909, 0.02495383284986019, -0.02372470125555992, -0.0022689425386488438, 0.021652519702911377, -0.05047198385000229, 0.027081387117505074, 0.001822356367483735, 0.03560991957783699, -0.07654215395450592, 0.03464890271425247, 0.03983033820986748, 0.007596711162477732, -0.00820134487003088, 0.016433056443929672, -0.04052489995956421, -0.05317716300487518, 0.019095338881015778, 0.025312190875411034, -0.02060031145811081, 0.023101920261979103, 0.022763198241591454, 0.05318830907344818, 0.022689035162329674, 0.04580517113208771, -0.02418431267142296, 0.005756509490311146, 0.0227394737303257, -0.008462236262857914, 0.014890947379171848, 0.025959135964512825, 0.0655631422996521, 0.049347080290317535, -0.0649702250957489, -0.004799894988536835, -0.02577640675008297, -0.021585550159215927, -0.029571639373898506, -0.03776778653264046, -0.03476656973361969, -0.04833543673157692, -0.011524934321641922, 0.01436570193618536, -0.010157293640077114, 0.025512751191854477, -0.020560992881655693, 0.008830257691442966, -0.07185208052396774, 0.008842254057526588, -0.06730465590953827, -0.03426032140851021, 0.023815058171749115, 0.01045922003686428, -0.0221498254686594, 0.016855722293257713, 0.02214805595576763, -0.00563858263194561, 0.037372421473264694, 0.014081068336963654, -0.000627673405688256, 0.03209219127893448, 0.01831839233636856, -0.01115434616804123, 0.007815935648977757, -0.03676748275756836, 0.04389002546668053, 0.02950260043144226, -0.08435370028018951, 0.046304523944854736, 0.05592359974980354, 0.11318342387676239, 3.902989192283712e-05, 0.003976206760853529, 0.03190291300415993, 0.026454634964466095, -0.030403388664126396, -0.07173648476600647, 0.0275344867259264, -0.018295731395483017, 0.008834141306579113, -0.053571369498968124, -0.011381423100829124, 0.037122730165719986, 0.021967831999063492, -0.05628304183483124, -0.06302008777856827, -0.029151905328035355, 0.01775461994111538, -0.010099999606609344, -0.007647380232810974, 0.004036938305944204, 0.019492236897349358, 0.03337069973349571, -0.023329518735408783, 0.07820428907871246, -0.017568793147802353, 0.013144304044544697, 0.0525190606713295, 0.0575278177857399, 0.021852001547813416, -0.018283449113368988, -0.012473837472498417, -0.010325700044631958, 0.0012296705972403288, -0.04114870727062225, 0.049336422234773636, 0.011148248799145222, -0.023351864889264107, 0.01849576085805893, 0.038280658423900604, -0.0712461918592453, -0.01973361149430275, -0.044761333614587784, -0.029651222750544548, 0.004280421882867813, -0.045621488243341446, 0.09187140315771103, -0.04828658699989319, -0.018675927072763443, -0.010195722803473473, 0.023510273545980453, 0.012555152177810669, 0.03710920363664627, 0.02312895841896534, 0.03566849231719971, -0.017556706443428993, 0.0016301128780469298, -0.01124767865985632, -0.02638448029756546, -0.021822530776262283, 0.0447160042822361, 0.025419902056455612, 0.013948207721114159, 0.06108173355460167, -0.08092902600765228, -0.04439651221036911, -0.06017359718680382, 0.04674016311764717, 0.010157673619687557, 0.01750018447637558, 0.014106757007539272, 0.017397280782461166, 0.028775108978152275, 0.04061347246170044, -0.015176225453615189, -0.06216379255056381, -0.06951109319925308, -0.0026321974582970142, -0.019868671894073486, 0.007292000576853752, 0.027097685262560844, -0.048658814281225204, 0.006863653659820557, 0.02216487191617489, -0.03659230098128319, 0.02679526060819626, -0.021725721657276154, -0.0010953237069770694, -0.01312750019133091, 0.01988554745912552, -0.005687573924660683, 0.01552630215883255, 0.00289959111250937, -0.0006070671952329576, -0.07300267368555069, -0.030238034203648567, 0.010913451202213764, -0.0185411237180233, 0.0035564254503697157, 0.009019523859024048, -0.007474066689610481, -0.00754526536911726, -4.561839159578085e-05, 0.017934652045369148, 0.035023387521505356, -0.05253135412931442, 0.042625412344932556, 0.04006103798747063, 0.020342931151390076, 0.011024750769138336, -0.02279829792678356, 0.039904262870550156, -0.06498732417821884, -0.006865274161100388, 0.010919824242591858, -0.0438656285405159, 0.007444495800882578, 0.020456699654459953, 0.007332334760576487, 0.006250091828405857, -0.015007092617452145, -0.05475427955389023, 0.02217233180999756, 0.09707270562648773, -0.01005181111395359, 0.016552360728383064, -0.00740497512742877, -0.034652285277843475, 0.009079323150217533, -0.03884193301200867, 0.01059007178992033, 0.005054936744272709, -0.004029028117656708, 0.014592057093977928, -0.03091176226735115, -0.02932140789926052, -0.04561452195048332, 0.028665395453572273, 0.040971480309963226, 0.01607353612780571, 0.008512832224369049, -0.041218094527721405, -0.03371405228972435, -0.024020763114094734, 0.03746791556477547, 0.047966256737709045, 0.010903412476181984, -0.04139113798737526, -0.0045763771049678326, 0.012038825079798698, -0.02330971322953701, 0.015643266960978508, 0.04083309695124626, 0.004894022364169359, -0.008949432522058487, -0.037692099809646606, -0.03239551931619644, 0.045114122331142426, -0.012821758165955544, -0.012918271124362946, -0.043928101658821106, 0.032840829342603683, 0.02697754092514515, -0.04787560924887657, -0.004240153357386589, -0.01916367933154106, -0.008400728926062584, -0.005713522434234619, -0.010850440710783005, 0.008764039725065231, -0.009628722444176674, 0.010193304158747196, 0.005497889593243599, 0.04360143095254898, 0.0290104690939188, 0.054670657962560654, 0.015213225036859512, -0.03969644382596016, 0.01732616126537323, -0.009322700090706348, 0.02114434354007244, -0.05047158896923065, -0.01013652328401804, -0.020307138562202454, -0.001544132479466498, 0.015356600284576416, -0.0475851371884346, -0.003982874099165201, -0.009103271178901196, 0.05216289684176445, -0.04030163213610649, -0.011333739385008812, 0.04742763563990593, 0.034940917044878006, 0.013490493409335613, -0.036716386675834656, 0.07834172248840332, 0.04623914882540703, 0.018064502626657486, -0.045583851635456085, 0.060875341296195984, -0.015086292289197445, -0.013840711675584316, 0.03470304235816002, 0.04566148295998573, 0.0011597158154472709, -0.010796240530908108, 0.021391738206148148, 0.028411371633410454, -0.04125775024294853, 0.04318983852863312, 0.02251148410141468, -0.05104152485728264, -0.018124330788850784, -0.0007521118968725204, 0.01972777210175991, 0.010831885039806366, -0.017963813617825508, 0.00930542778223753, -0.036153268069028854, -0.0505196675658226, 0.010095151141285896, -0.04545662924647331, 0.03737304359674454, 0.002340928418561816, -0.035730257630348206, 0.014667278155684471, 0.008507287129759789, -0.0029444796964526176, -0.01236264780163765, 0.03737995773553848, 0.04198315739631653, -0.01683664135634899, -0.006140850018709898, -0.04284239187836647, -0.008289591409265995, -0.03510654345154762, -0.01913795992732048, -0.025934631004929543, 0.02991476282477379, -0.05719323828816414, 0.013294177129864693, 0.013730845414102077, 0.021393723785877228, 0.030385473743081093, -0.038634516298770905, 0.016872910782694817, 0.029059814289212227, 0.004847659729421139, 0.054621849209070206, 0.02622702717781067, 0.022165508940815926, 0.025115272030234337, 0.003773147240281105, -0.00013876912998966873, 0.03559422865509987, 0.02754603698849678, -0.03608343377709389, 0.018636204302310944, -0.045546598732471466, -0.023706290870904922, -0.04214908927679062, 0.00893162190914154, 0.0547931082546711, -0.0430007129907608, -0.0013727123150601983, -0.019893551245331764, -0.030532920733094215, -0.06574578583240509, 0.05074842646718025, -0.004824800882488489, 0.0021483413875102997, 0.020576877519488335, 0.003385282587260008, -0.021614419296383858, -0.08725608885288239, -0.056396182626485825, -0.08448965102434158, -0.05506547540426254, -0.030453486368060112, -0.016547808423638344, 0.04787944629788399, 0.07378087937831879, 0.056122612208127975, -0.04297199100255966, -0.05870511010289192, 0.04280991852283478, -0.017878400161862373, -0.05333738774061203, 0.001618281239643693, -0.06375809758901596, 0.03691989183425903, 0.018877221271395683, 0.04801151901483536, -0.020393280312418938, -0.02034175395965576, 0.017661742866039276, -0.07154034078121185, -0.012733208946883678, -0.012135226279497147, -0.052409131079912186, -0.015307759866118431, 0.0048771691508591175, 0.03577109053730965, 0.09510818123817444, -0.06818883866071701, 0.015373767353594303, 0.029422074556350708, -0.029751241207122803, 0.05079738050699234, 0.03086705505847931, -0.028877142816781998, 0.022521670907735825, -0.045026011765003204, -0.02118918113410473, 0.0218913983553648, 0.014961226843297482, -5.713405698770657e-05, -0.005503848660737276, 0.05765504762530327, -0.0037858309224247932, 0.02410776913166046, -0.02111600711941719, -0.02422180585563183, 0.0050227222964167595, 0.012237816117703915, -0.019557209685444832, -0.05280531942844391, 0.026608165353536606, 0.00639713229611516, 0.0024344732519239187, 0.010603251866996288, -0.020162375643849373, -0.016201095655560493, 0.006738138385117054, 0.05487949028611183, 0.0005698130116797984, 0.05158922076225281, -0.013791133649647236, 0.017569005489349365, -0.03301624581217766, -0.012689064256846905, -0.024486571550369263, 0.037785470485687256, -0.04342205822467804, -0.03660697489976883, 0.0004170486645307392, 0.00725180609151721, -0.02983843721449375, 0.08136755228042603, -0.027667349204421043, -0.005279478617012501, -0.05188515782356262, -0.015521376393735409, 0.008956925012171268, -0.04741872474551201, 0.038155198097229004, -0.04407234117388725, 0.024176007136702538, -0.037952858954668045, -0.021443696692585945, -0.023215804249048233, -0.025918234139680862, -0.03803164139389992, 0.009271016344428062, 0.013934290036559105, -0.006307588890194893, 0.10413765162229538, 0.04201919957995415, 0.03521605581045151, -0.04081948846578598, -0.03962310403585434, -0.031802065670490265, 0.027915624901652336, -0.023932363837957382, 0.0059822676703333855, 0.011074645444750786, -0.015337517485022545, -0.0263056680560112, -0.039176952093839645, 0.07241053879261017, -0.025588160380721092, 0.00036717887269333005, 0.0512235127389431, 0.052833374589681625, 0.056751757860183716, 0.0006862719310447574, -0.03717155009508133, -0.04655462130904198, -0.02384798787534237, 0.07667730003595352, 0.06425092369318008, -0.009028569795191288, -0.058156926184892654, -0.006338919047266245, 0.013434655033051968, 0.02401171810925007, 0.03922107815742493, -0.010409368202090263, 0.03285791724920273, -0.024784471839666367, 0.05234086140990257, -0.004626173060387373, -0.0016643691342324018, -0.08181062340736389, -0.016887949779629707, 0.03144665062427521, -0.07752760499715805, -0.013268198817968369, -0.02601007930934429, -0.06845599412918091, -0.029691915959119797, -0.007359729614108801, 0.014776676893234253, 0.02546454221010208, -0.0014413149328902364, -0.021043654531240463, -0.0013637153897434473, -0.03427042067050934, 0.010171559639275074, 0.02670375443994999, -0.0319516621530056, 0.09769332408905029, -0.040732383728027344, 0.029234787449240685, -0.015274462290108204, -0.03250695765018463, -0.032357364892959595, 0.015325648710131645]\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"Hey , who are you ??\"))\n",
    "print(embeddings.embed_query(\"Hey , who are you ??\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/introduction/', 'title': 'Redirecting...', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n')],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/workflows/', 'title': 'Redirecting...', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n')],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/how-tos/map-reduce/', 'title': 'Redirecting...', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n')]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls=[\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/workflows/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/how-tos/map-reduce/\"\n",
    "]\n",
    "\n",
    "docs=[WebBaseLoader(url).load() for url in urls]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "## Add alll these text to vectordb\n",
    "\n",
    "vectorstore=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='retriever_vector_db_blog', description='Search and run information about Langgraph', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000026EFBA29C60>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000026EE3547A10>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000026EFBA2B100>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000026EE3547A10>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"what is langgraph\")\n",
    "\n",
    "### Retriever To Retriever Tools\n",
    "# from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retriever_vector_db_blog\",\n",
    "    \"Search and run information about Langgraph\"\n",
    ")\n",
    "\n",
    "retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={'source': 'https://medium.com/munchy-bytes/exploring-langchain-ff13fff63340', 'title': 'Exploring LangChain. In recent years, language models have… | by Fatima Mubarak | Tech Blog | Medium', 'description': 'Exploring LangChain In recent years, language models have become more advanced, allowing us to tackle complex tasks and extract information from large documents. However, these models have a limit on …', 'language': 'en'}, page_content='Exploring LangChain. In recent years, language models have… | by Fatima Mubarak | Tech Blog | MediumSitemapOpen in appSign upSign inMedium LogoWriteSearchSign upSign inTech Blog·Changing the way organizations look at dataExploring LangChainFatima Mubarak9 min read·Feb 12, 2024--ListenShareIn recent years, language models have become more advanced, allowing us to tackle complex tasks and extract information from large documents. However, these models have a limit on the amount of context they can consider, which can be tricky when dealing with lots of information. To overcome this challenge, LLM chains have emerged. They simplify the process of chaining multiple LLM calls together, making it easier to handle large volumes of data.Press enter or click to view image in full sizeWhat is Lang Chain? (AWS)LLM chains use different language model components to process information and generate responses in a unified way. In this article, we will discuss different components and conventions in Lang Chain.What is Lang Chain?Lang Chain provides AI developers with tools to connect language models with external data sources.Press enter or click to view image in full sizeBuilding application with Lang Chain (LinkedIn article)LLMs are large deep-learning models pre-trained on large amounts of data that can generate responses to user queries by answering questions or creating images from text-based prompts.What is the prompt?A language model prompt is a collection of user-provided instructions or input that guides the model’s response, assisting it in understanding the context and producing appropriate and meaningful output, such as answering questions, completing phrases, or engaging in a conversation.from langchain.prompts.prompt import PromptTemplateexample_template = \"\"\"Here\\'s an example of an interaction:Q: {example_q}A: {example_a}\"\"\"example_prompt = PromptTemplate.from_template(example_template)What is a Vector store?Compared to traditional databases, vector stores handle high-dimensional vector data more efficiently. They excel at finding similar data points, scale effortlessly to handle large amounts of data, and are compatible with common machine learning tools. This makes them invaluable assets for tasks such as recommendation systems, text analysis, chatbots, and more.Press enter or click to view image in full sizeVector store(Lang chain)One of the most frequent methods for storing and searching unstructured data is to embed it and save the generated embedding vectors, followed by embedding the unstructured query and retrieving the embedding vectors that are ’most similar’ to the embedded query. A vector store stores embedded data and performs vector searches for you.Vector DatabasesLang Chain supports async operations on vector stores. All the methods might be called using their packages.ChromaChroma is an open-source embedding database. Chroma makes it simple to create LLM apps by making knowledge, facts, and abilities connected for LLMs.pip install chromadbfrom langchain_community.vectorstores import Chroma# Load the document, split it into chunks, embed each chunk and load it into the vector store.raw_documents = TextLoader(\\'../../../state_of_the_union.txt\\').load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)documents = text_splitter.split_documents(raw_documents)db = Chroma.from_documents(documents, OpenAIEmbeddings())2. FAISSFacebook AI Similarity Search (FAISS) is a library for efficient similarity search. It offers methods for searching sets of vectors of any size, including ones that may not fit in RAM. It also includes support code for evaluation and parameter adjustment.from langchain_community.embeddings.openai import OpenAIEmbeddingsfrom langchain_community.vectorstores import FAISSembeddings = OpenAIEmbeddings()texts = [\"FAISS is an important library\", \"LangChain supports FAISS\"]faiss = FAISS.from_texts(texts, embeddings)There is a variety of vector store types available, offering functionalities to suit different needs. You can explore more vector store types and their capabilities at https://python.langchain.com/docs/integrations/vectorstores/ .What Are Chains in AI Text Generation in LangChain?What are chains?Chains refer to sequences of calls — whether to an LLM, a tool, or a data preprocessing step.Press enter or click to view image in full sizeLang Chain features at a glance(https://www.packtpub.com/)In Lang Chain, a chain functions similar to a necklace, where each bead contributes a unique element to the overall structure. Chains have various components that the Lang Chain library offers, making our work with LLMs easier and more efficient.Why we need chains?Chains combine LLMs with other components, creating applications by executing a sequence of functions.There are several types of chains, each designed to deal with certain problems and make specific use of language models’ strengths. This section looks at frequently utilized LLM chain types.Components of chains in LangChainLLMs (Large Language Models): These are core processing units used for tasks like generation, translation, summarization, and question answering.Memory: Stores information between nodes or across chain runs for context continuity.Tools: Perform specific tasks like summarization, sentiment analysis, or data retrieval.Agents: Act as decision-makers, choosing which tools to use based on input and context.Data Retrieval Components: Fetch data from internal databases, external APIs, or local files.Types of Chains?1. Conversational Retrieval ChainIt is a type of chain that responds to a query by retrieving documents related to the query. This is only one of many ways that Retrieval-Augmented Generation may be done.However, in addition to responding to your most recent question, it will use the conversation history to enhance the RAG’s quality.chain = ConversationalRetrievalChain(    combine_docs_chain= StuffDocumentsChain(...),    retriever= vectorstore.as_retriever(),    question_generator=LLMChain(llm=OpenAI(), prompt=prompt),)2. LLM ChainA PromptTemplate along with a language model form an LLMChain. The input key values and, if available, memory key values are used to prepare the prompt template. The formatted string is then passed to LLM, and the LLM output is returned.chain = LLMChain(llm=OpenAI(), prompt=prompt)3. Retrieval QAThe process of extracting the most relevant documents from a significant amount of data is known as retrieval. In question-answering (QA), a system receives a question and is required to provide the closet response.retrievalQA = RetrievalQA.from_llm(llm=OpenAI(), retriever=vectorstore.as_retriever())4. Stuff Documents ChainThis chain starts by merging a collection of documents into a single string. It does this by using document_prompt to format each document into a string and document_separator for connecting them all together. The new string is then added to the inputs with the variable name set. The llm_chain receives those inputs.chain = StuffDocumentsChain(    llm_chain = LLMChain(llm=llm, prompt=prompt),    document_prompt=document_prompt,    document_variable_name=document_variable_name)Additionally, there are other types of document chains such as MapReduceChain, ReduceDocumentsChain, RefineDocumentsChain, and various other chain types.Retrieval-Augmented Generative Models(RAG)Let’s see how to create a “retrieval-augmented generation” chain by integrating a retrieval step into an LLM and prompt. Retrieval Augmented Generation (RAG) is the process of bringing the relevant data and inserting it into the model prompt.Typically, a RAG consists of two main parts:Indexing: A pipeline for ingesting and indexing data from a source. Usually, this takes place offline.Generation and retrieval: the real RAG chain, which receives the user query at runtime, extracts relevant data from the index, and then provides it to the model.Press enter or click to view image in full sizeData indexing in typical RAGs(thetechbuffet)Indexing :Load: Our data must first be loaded. To do this, DocumentLoaders are used.Split: Text splitters divide long documents into smaller sections. Since large chunks are more difficult to search through and won’t fit in a model’s limited context window, this is helpful for both indexing data and feeding it into a model.Store: In order to be able to search over our splits later, we need a place to index and store them. Embeddings and VectorStore are frequently used for this.Retrieval and generation :Retrieve: A Retriever is used to retrieve relevant data from memory based on user input.Generate: By utilizing a prompt that contains both the question and the returned data, LLM generates a response.Enhancing performance using MemoryA conversational interface is found in most LLM programs. Being able to reference information that was introduced previously in the discussion is crucial. A conversational system should at least be able to open a window with previous messages directly. In order to do tasks like maintaining data on entities and their relationships, a more sophisticated system will require an updating model.We refer to this ability to keep details of previous interactions as “memory”. Lots of utilities for adding a system’s memory are available from LangChain. These tools can be smoothly integrated into a chain or utilized alone.Press enter or click to view image in full sizeWhat is LangChain and Why it is damn popular? (collabnix.com)The two fundamental functions of a memory system are writing and reading. Keep in mind that each chain specifies some basic execution logic that requires specific inputs. While some of these inputs may originate from memory, others may come directly from the user.Memory Types?There are many different types of memory. They are all helpful in different situations and have different parameters and return types.Conversation Buffer Langchain’s Buffer Memory is a basic memory buffer that stores the conversation history. It has a buffer property that returns a list of messages from the chat memory. This type of memory is important for storing and retrieving the most recent history of a discussion.from langchain.memory import ConversationBufferMemorymemory = ConversationBufferMemory()memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})memory.load_memory_variables({})# use in chainconversation = ConversationChain(    llm= OpenAI(temperature=0),    verbose=True,    memory=ConversationBufferMemory())Conversation Buffer WindowThis type of memory adds a window to the buffer memory that remembers only K number of previous interactions. This reduces the number of tokens utilized, but it loses the context of any inputs that came before the previous K interactions.from langchain.memory import ConversationBufferWindowMemorymemory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=1)Conversation SummaryConversation summary memory creates an overview of conversations overtime. The summary is continuously updated and can be integrated into prompt/chains. This approach is useful in long conversations where including the entire message history becomes impractical due to over-consumption of tokens.from langchain.memory import ConversationSummaryMemorymemory = ConversationSummaryMemory(llm=OpenAI(temperature=0))Conversation Summary BufferThis type of memory preserves a buffer of recent interactions in memory, but instead of completely clearing previous interactions, it combines them into a summary and uses both. It determines when to flush interactions based on token length rather than the number of interactions.from langchain.memory import ConversationSummaryBufferMemorymemory = ConversationSummaryBufferMemory(    llm=llm, max_token_limit=10, return_messages=True)Langchain offers a diverse array of memory types accessible via https://python.langchain.com/docs/modules/memory/. Additionally, you can explore customization options and learn how to utilize multiple memory classes in the provided references.[1] Custom Memory : https://python.langchain.com/docs/modules/memory/custom_memory[2] Multiple Memory Classes: https://python.langchain.com/docs/modules/memory/multiple_memorySample Usage:# installationspip install langchainpip install faiss-cpupip install beautifulsoup4pip install langchain-corepip install langchain-openaipip install langchain-community# Import necessary librariesfrom langchain_openai import ChatOpenAIfrom langchain_openai import OpenAIEmbeddingsfrom langchain.chains import ConversationChainfrom langchain_community.vectorstores import FAISSfrom langchain.memory import ConversationBufferMemoryfrom langchain_community.document_loaders import WebBaseLoaderfrom langchain.text_splitter import RecursiveCharacterTextSplitterfrom langchain.chains.combine_documents import create_stuff_documents_chain# Set the OpenAI API keyOPENAI_API_KEY = \"...\"# Initialize the ChatOpenAI object for interacting with the OpenAI APIllm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)# Initialize the WebBaseLoader to load documents from a URLloader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")docs = loader.load()  # Load documents from the specified URL# Initialize the OpenAIEmbeddings for generating embeddingsembeddings = OpenAIEmbeddings()# Initialize the RecursiveCharacterTextSplitter to split documents into segmentstext_splitter = RecursiveCharacterTextSplitter()documents = text_splitter.split_documents(docs)  # Split documents into segmentsvector = FAISS.from_documents(documents, embeddings)  # Generate vector representations of documents# Define a template for generating promptstemplate = (    \"Combine the chat history and follow up question into \"    \"a standalone question. Chat History: {chat_history}\"    \"Follow up question: {question}\")# Create a PromptTemplate instance from the templateprompt = PromptTemplate.from_template(template)# Initialize the ConversationChain for managing conversation flowconversation = ConversationChain(    llm=llm,  # OpenAI language model    verbose=True,  # Enable verbose mode for logging    memory=ConversationBufferMemory()  # Use ConversationBufferMemory for storing conversation history)# Perform prediction based on the input promptconversation.predict(input=\"Hello, I am Fatima\")ConclusionIn summary, Lang-Chain enables developers to create advanced AI systems by providing a solid framework for linking language models with external data sources, efficiently handling vector data, and effectively managing memory. Lang-Chain, with its diverse range of features and flexible architecture, is well-suited to play a critical role in improving the capabilities of AI-powered applications.References[1] LangChain Documentation. Available at: https://python.langchain.com[2] Yıldırım, S. (2023, June 25). 4 Memory Types of LangChain to Enhance the Performance of LLMs. Medium. Available at: https://sonery.medium.com/4-memory-types-of-langchain-to-enhance-the-performance-of-llms-bda339d2e904[3] Sakamoto, A. (2023, July 24). LangChain Chains: What is LangChain. Kanaries. Available at: https://docs.kanaries.net/articles/langchain-chains-what-is-langchain[4] DataCamp. (n.d.). The Top 5 Vector Databases. DataCamp Blog. Available at: https://www.datacamp.com/blog/the-top-5-vector-databasesArtificial IntelligenceTechnologyMachine Learning----Published in Tech Blog87 followers·Last published\\xa0Nov 9, 2025Changing the way organizations look at dataWritten by Fatima Mubarak76 followers·20 followingData scientist @montymobile | In my writing, I explore the fields of data science , machine learning and related topics.No responses yetHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')],\n",
       " [Document(metadata={'source': 'https://medium.com/@vikrampande783/introduction-to-langchain-9e09aae37e62', 'title': 'Introduction to LangChain. LangChain Concepts and Applications… | by Vikram Pande | Medium', 'description': 'Introduction to LangChain LangChain Concepts and Applications with code examples In this era of Artificial Intelligence, LLMs, and GenAI, it is essential to understand the tools used in this space …', 'language': 'en'}, page_content='Introduction to LangChain. LangChain Concepts and Applications… | by Vikram Pande | MediumSitemapOpen in appSign upSign inMedium LogoWriteSearchSign upSign inIntroduction to LangChainVikram Pande6 min read·Oct 20, 2024--1ListenShareLangChain Concepts and Applications with code examplesIn this era of Artificial Intelligence, LLMs, and GenAI, it is essential to understand the tools used in this space. LangChain is a framework designed to simplify the development of GenAI applications and is a highly sought-after skill in today’s AI market. This is not about Natural Language Processing theory, but rather an engineering perspective. Companies are looking for skills in Prompting, LLMs, RAG, LangChain, LlamaIndex, and Vector Databases, in addition to classical machine learning, deep learning theory, coding skills, and domain knowledge in areas like computer vision and NLP. However, these GenAI skills are relatively easy to learn and implement. It is good to have knowledge along with a solid machine-learning foundation. Let’s get started:What is LangChain?LangChain is an open-source software framework that integrates Large Language Models (LLMs) into domain-specific applications. Released in October 2022, LangChain became popular in the industry and research for its easy-to-use interface. It is designed to simplify the development, productionization, and deployment of LLM-powered applications. It has a set of building blocks for almost every stage of the LLM application lifecycle. Another framework similar to LangChain is LlamaIndex but I am not going to cover LlamaIndex in this blog.Press enter or click to view image in full sizeLangChainLangChain Features and Open-source Libraries:langchain-core Base abstractions and LangChain Expression Language (LCEL) for composing Chains.langchain-community Third-party integrations and partner packages for extensibility such as langchain-openai , lanchain-anthropic , etc.langchain Chains, Agents, and retrieval strategies for cognitive architecture.LangGraph: multi-actor applications with LLMs by modeling steps as edges and nodes in a graph.LangServe: Deploy LangChain Chains as REST APIs.LangSmith: Platform to debug, test, evaluate, and monitor LLM applications.There is extensive, detailed documentation on LangChain available on their official site. In this blog, I will only cover high-level, important components and concepts that are sufficient to get started with using LangChain in real-life applications.Key Concepts and ComponentsPress enter or click to view image in full sizeLangChain ComponentsYou can find detailed documentation of key LangChain concepts hereTool: Tools are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models. Tools are needed whenever you want a model to control parts of your code or call out to external APIs.Output Parser: Output parsers are classes that help structure language model responses. They are responsible for taking the output of an LLM and transforming it into a more suitable format.Text Splitter: Text splitters divide a document or text into smaller chunks or segments. LangChain has a number of built-in document transformers that can split, combine, and filter documents.Prompt: LangChain provides tooling to create and work with prompt templates. Prompt templates are predefined recipes for generating prompts for language modelsModel: Traditional LLMsChat Model: Language models that use a sequence of messages as inputs and return chat messages as outputs, These are traditionally newer models. Chat models support the assignment of distinct roles to conversation messages, helping to distinguish messages from the AI, users, and instructions such as system messages.Embeddings: Embeddings class to provide embeddings/vectors for a given document. It provides a standard interface for different embedding model providers such as HuggingFace, OpenAI, etc.Retriever: Retrievers accept a string query as input and return a list of Documents as output. LangChain provides several advanced retrieval types and also integrates with many third-party retrieval services.Document Loader: Provides a Load method for loading data as documents from a source.Vector Store: A vector store stores embedded data and performs vector search. Embedding and storing embedding vectors is one of the most common ways to store and search over unstructured data. They are also used in RAG applications.Index: A data structure that organizes and stores data to facilitate quick and efficient searches.Agents: Agents are the decision-making components that decide the plan of action or process.Chains: They are sequences of calls, whether to an LLM, a tool, or a data preprocessing step. They integrate various components into a user-friendly interface, including the model, prompt, memory, output parsing, and debugging capabilities.Memory: This feature records past interactions with a language model, providing context for future interactions.Callbacks: LangChain provides a callbacks system that allows you to hook into the various stages of your LLM application. This is useful for logging, monitoring, and streaming.LangChain and Retrieval Augmented Generation (RAG)Retrieval-augmented generation (RAG) is an effective technique for tackling one of the key challenges faced by Large Language Models (LLMs): hallucinations. By incorporating external knowledge sources, RAG systems enable LLMs to access relevant, factual information during the generation process. This results in outputs that are more accurate, reliable, and contextually appropriate. LangChain offers useful abstractions for building RAG systems. With its retrieval components, developers can seamlessly integrate external data sources, such as documents or databases, into their LLM-driven applications. This allows models to retrieve and utilize pertinent information during generation, leading to more precise and reliable outputs. I have shown an example proof of concept of using LLMs with RAG on Databricks that can be found in this blog.Prompt TemplateA prompt template consists of a string template. It accepts a set of parameters from the user that can be used to generate a prompt for a language model. Example PromptTemplate can be found here.Example CodeI am going to show you a few simple and common example use cases using LangChain. They are mainly focused on the Summarization chain and Question-Answer chain. You’ll need to have free credits in your OpenAI account. You can also use models from Meta or Anthropic.You will need to install LangChain on your system by simply using pip install langchain it in your Python environment. You can find more details here.You will need to have an OpenAI account. I am using one OPENAI_API_KEYthat is stored in environment variablesin my system. It is easy to generate a key from an OpenAI account. You can also externally define your key as a string as shown below in code. Some of the code snippets are copied from docs.from langchain_openai import ChatOpenAIfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholderchat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.2)prompt = ChatPromptTemplate.from_messages(    [        (            \"system\",            \"You are a helpful assistant. Answer all questions to the best of your ability.\",        ),        MessagesPlaceholder(variable_name=\"messages\"),    ])chain = prompt | chatchain.invoke(    {        \"messages\": [            HumanMessage(                content=\"Translate this sentence from English to French: I love programming.\"            ),            AIMessage(content=\"J\\'adore la programmation.\"),            HumanMessage(content=\"What did you just say?\"),        ],    })###### OUTPUT ######AIMessage(content=\\'I said \"J\\\\\\'adore la programmation,\" which means \"I love programming\" in French.\\')######### Summarization Chain Example #############from langchain.chains.summarize import load_summarize_chainfrom langchain_community.document_loaders import WebBaseLoaderfrom langchain_openai import ChatOpenAIloader = WebBaseLoader(\"https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\")docs = loader.load()llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-1106\")chain = load_summarize_chain(llm, chain_type=\"stuff\")chain.run(docs)##### OUTPUT #####The blog post by Lilian Weng titled \"Scaling Diffusion Models for Video Generation\" (April 12, 2024) explores how diffusion models are adapted to create high-quality video content. It discusses techniques like frame interpolation, temporal consistency, and how latent space and attention mechanisms are used to maintain coherence across frames. The post also highlights challenges like long-term dependencies and introduces advanced architectures that scale diffusion models to handle the complexity of video data. It offers insights into advancements in generative AI for video creation.For more details, visit: [Lilian Weng\\'s post](https://lilianweng.github.io/posts/2024-04-12-diffusion-video/).######### Question-Answer Chain Example #############from langchain_community.chat_models import ChatOpenAIfrom langchain.chains import LLMChainfrom langchain_core.prompts import PromptTemplateOPENAI_SECRET = \"your_openai_key\" #if not stored in env variableprompt = PromptTemplate(template=\"Question: {question}\\\\nAnswer:\",input_variables=[\"question\"]) # PromptTemplatellm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, api_key=OPENAI_SECRET) #Call LLMchain = LLMChain(llm=llm, prompt=prompt) #Create Chainchain.run(\"What is Halloween?\") #Chain Run ##### OUTPUT #####Halloween is a holiday celebrated annually on October 31, originating from ancient Celtic festivals like Samhain. It marks the end of the harvest season and the beginning of winter, historically seen as a time when the boundary between the living and the dead thins. Modern Halloween traditions include dressing in costumes, trick-or-treating, carving pumpkins into jack-o\\'-lanterns, and attending parties. It\\'s a fun, spooky celebration known for embracing themes of ghosts, witches, and the supernatural.Note: This code was developed in version 0.3.4 and some of the LangChain components may become redundant or deprecated in future releases.ReferencesLangChain API DocumentationBuilding LLMs for Production by Louis-Francois Bouchard and Louie PetersLlmLangchainAIPrompt Engineering----1Written by Vikram Pande93 followers·91 followingMachine Learning Engineer | Multimodal and Generative AI (Vision + Language) Enthusiast | Currently learning LLMs and MLOps | MS @ NCSUResponses (1)See all responsesHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain_urls=[\n",
    "    \"https://medium.com/munchy-bytes/exploring-langchain-ff13fff63340\",\n",
    "    \"https://medium.com/@vikrampande783/introduction-to-langchain-9e09aae37e62\",\n",
    "]\n",
    "\n",
    "docs=[WebBaseLoader(url).load() for url in langchain_urls]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "## Add alll these text to vectordb\n",
    "\n",
    "vectorstorelangchain=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "\n",
    "retrieverlangchain=vectorstorelangchain.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool_langchain=create_retriever_tool(\n",
    "    retrieverlangchain,\n",
    "    \"retriever_vector_langchain_blog\",\n",
    "    \"Search and run information about Langchain\"\n",
    ")\n",
    "\n",
    "tools=[retriever_tool,retriever_tool_langchain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\")\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_classic import hub\n",
    "# from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edges\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\")\n",
    "\n",
    "    # LLM with tool and validation\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # question = messages[0].content\n",
    "\n",
    "    question = None\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg,HumanMessage):\n",
    "            question = msg.content\n",
    "            break\n",
    "    if question is None:\n",
    "        question = messages[0].content\n",
    "    \n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"rewrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated message\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    # question = messages[0].content\n",
    "\n",
    "    question = None\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg,HumanMessage):\n",
    "            question = msg.content\n",
    "            break\n",
    "    if question is None:\n",
    "        question = messages[0].content\n",
    "\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    docs = last_message.content\n",
    "\n",
    "    # Prompt\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\")\n",
    "\n",
    "    # Post-processing\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [AIMessage(content=response)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    # question = messages[0].content\n",
    "\n",
    "    question = None\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg,HumanMessage):\n",
    "            question = msg.content\n",
    "            break\n",
    "    if question is None:\n",
    "        question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\")\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [HumanMessage(content=response.content)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", agent)  # agent\n",
    "retrieve = ToolNode([retriever_tool,retriever_tool_langchain])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
    "workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
    "workflow.add_node(\n",
    "    \"generate\", generate\n",
    ")  # Generating a response after we know the documents are relevant\n",
    "# Call agent node to decide to retrieve or not\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"messages\":\"What is Langgraph?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS RELEVANT---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is Langchain?', additional_kwargs={}, response_metadata={}, id='f7c0fb38-f3cd-4a7b-8b68-304bde5e3261'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever_vector_langchain_blog', 'arguments': '{\"query\": \"What is Langchain?\"}'}, '__gemini_function_call_thought_signatures__': {'61d5c1c7-e879-4eba-92ff-abd062e302df': 'Cr4CAdHtim+iUKmiJOpbB4QFooj7QRnrM8dQNJBQQHqdo5sq++5IglXUWsBUh8wfko9XPTUyDkLVvKlfgOI9/JNhUxAcq6lS68axiCGHFwAfpAsg3bXG9mDZJHe8QxlZFXg6a5vdcrQPc8Ci3BzrXNNSVH7tzQNaN0cWLlbVuESNVrYf4xD37c7WxBsJzZoaNBcq36CbadeRSH3lJIQbQplVpAGYD9jPNUzwgHImEuPyB+hi+88m275+mqg1oUF7uU3WIQ6kG8cuAu4Y0FVL8c0t42iLp1Ckm3ff1X9POFC0y+qe3DQBbimEY6ahHs/SvRQ1eSqgkr9iL3AUD4f8/UFQD19igFEy9WP3VK5ZKa7q+QfxmRfzGQQ/KGfsYjbnl97d3ELTSQkipzgkmDI42DO8yw9o+4qpjBTll9FtDZ7y'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--60e414f5-cf6d-4074-894c-bf1b2f3ad2a2-0', tool_calls=[{'name': 'retriever_vector_langchain_blog', 'args': {'query': 'What is Langchain?'}, 'id': '61d5c1c7-e879-4eba-92ff-abd062e302df', 'type': 'tool_call'}], usage_metadata={'input_tokens': 103, 'output_tokens': 90, 'total_tokens': 193, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 65}}),\n",
       "  ToolMessage(content='skills are relatively easy to learn and implement. It is good to have knowledge along with a solid machine-learning foundation. Let’s get started:What is LangChain?LangChain is an open-source software framework that integrates Large Language Models (LLMs) into domain-specific applications. Released in October 2022, LangChain became popular in the industry and research for its easy-to-use interface. It is designed to simplify the development, productionization, and deployment of LLM-powered applications. It has a set of building blocks for almost every stage of the LLM application lifecycle. Another framework similar to LangChain is LlamaIndex but I am not going to cover LlamaIndex in this blog.Press enter or click to view image in full sizeLangChainLangChain Features and Open-source Libraries:langchain-core Base abstractions and LangChain Expression Language (LCEL) for composing Chains.langchain-community Third-party integrations and partner packages for extensibility such as\\n\\nIntroduction to LangChain. LangChain Concepts and Applications… | by Vikram Pande | MediumSitemapOpen in appSign upSign inMedium LogoWriteSearchSign upSign inIntroduction to LangChainVikram Pande6 min read·Oct 20, 2024--1ListenShareLangChain Concepts and Applications with code examplesIn this era of Artificial Intelligence, LLMs, and GenAI, it is essential to understand the tools used in this space. LangChain is a framework designed to simplify the development of GenAI applications and is a highly sought-after skill in today’s AI market. This is not about Natural Language Processing theory, but rather an engineering perspective. Companies are looking for skills in Prompting, LLMs, RAG, LangChain, LlamaIndex, and Vector Databases, in addition to classical machine learning, deep learning theory, coding skills, and domain knowledge in areas like computer vision and NLP. However, these GenAI skills are relatively easy to learn and implement. It is good to have knowledge along with a solid\\n\\nChains.langchain-community Third-party integrations and partner packages for extensibility such as langchain-openai , lanchain-anthropic , etc.langchain Chains, Agents, and retrieval strategies for cognitive architecture.LangGraph: multi-actor applications with LLMs by modeling steps as edges and nodes in a graph.LangServe: Deploy LangChain Chains as REST APIs.LangSmith: Platform to debug, test, evaluate, and monitor LLM applications.There is extensive, detailed documentation on LangChain available on their official site. In this blog, I will only cover high-level, important components and concepts that are sufficient to get started with using LangChain in real-life applications.Key Concepts and ComponentsPress enter or click to view image in full sizeLangChain ComponentsYou can find detailed documentation of key LangChain concepts hereTool: Tools are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be\\n\\nExploring LangChain. In recent years, language models have… | by Fatima Mubarak | Tech Blog | MediumSitemapOpen in appSign upSign inMedium LogoWriteSearchSign upSign inTech Blog·Changing the way organizations look at dataExploring LangChainFatima Mubarak9 min read·Feb 12, 2024--ListenShareIn recent years, language models have become more advanced, allowing us to tackle complex tasks and extract information from large documents. However, these models have a limit on the amount of context they can consider, which can be tricky when dealing with lots of information. To overcome this challenge, LLM chains have emerged. They simplify the process of chaining multiple LLM calls together, making it easier to handle large volumes of data.Press enter or click to view image in full sizeWhat is Lang Chain? (AWS)LLM chains use different language model components to process information and generate responses in a unified way. In this article, we will discuss different components and conventions in', name='retriever_vector_langchain_blog', id='2c820143-192f-4524-abbb-e6e01c3036b2', tool_call_id='61d5c1c7-e879-4eba-92ff-abd062e302df'),\n",
       "  AIMessage(content='LangChain is an open-source software framework designed to integrate Large Language Models (LLMs) into domain-specific applications. Released in October 2022, it quickly became popular for its easy-to-use interface. Its primary purpose is to simplify the development, productionization, and deployment of LLM-powered applications.', additional_kwargs={}, response_metadata={}, id='a0396717-011e-4262-bbaf-143b34a1f075')]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"What is Langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is Machine learning?', additional_kwargs={}, response_metadata={}, id='1b524fba-4f87-47ac-81ae-e7844a33237b'),\n",
       "  AIMessage(content='I can only answer questions related to Langchain and Langgraph. I cannot answer general questions about Machine Learning. ', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--ecbb2516-d9ae-4270-866c-8d9c1a1608e6-0', usage_metadata={'input_tokens': 103, 'output_tokens': 22, 'total_tokens': 125, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"What is Machine learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"messages\":\"Tell me about Langgraph ecosystem\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
